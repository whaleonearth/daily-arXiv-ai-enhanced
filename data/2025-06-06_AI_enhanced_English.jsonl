{"id": "2506.04263", "pdf": "https://arxiv.org/pdf/2506.04263", "abs": "https://arxiv.org/abs/2506.04263", "authors": ["Alan Mitkiy", "James Smith", "Hana Satou", "Hiroshi Tanaka", "Emily Johnson", "F Monkey"], "title": "Dynamic Epsilon Scheduling: A Multi-Factor Adaptive Perturbation Budget for Adversarial Training", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Adversarial training is among the most effective strategies for defending\ndeep neural networks against adversarial examples. A key limitation of existing\nadversarial training approaches lies in their reliance on a fixed perturbation\nbudget, which fails to account for instance-specific robustness\ncharacteristics. While prior works such as IAAT and MMA introduce\ninstance-level adaptations, they often rely on heuristic or static\napproximations of data robustness. In this paper, we propose Dynamic Epsilon\nScheduling (DES), a novel framework that adaptively adjusts the adversarial\nperturbation budget per instance and per training iteration. DES integrates\nthree key factors: (1) the distance to the decision boundary approximated via\ngradient-based proxies, (2) prediction confidence derived from softmax entropy,\nand (3) model uncertainty estimated via Monte Carlo dropout. By combining these\ncues into a unified scheduling strategy, DES tailors the perturbation budget\ndynamically to guide more effective adversarial learning. Experimental results\non CIFAR-10 and CIFAR-100 show that our method consistently improves both\nadversarial robustness and standard accuracy compared to fixed-epsilon\nbaselines and prior adaptive methods. Moreover, we provide theoretical insights\ninto the stability and convergence of our scheduling policy. This work opens a\nnew avenue for instance-aware, data-driven adversarial training methods.", "AI": {"tldr": "This paper introduces Dynamic Epsilon Scheduling (DES), a novel method that adaptively adjusts adversarial perturbation budgets during training, improving adversarial robustness and standard accuracy.", "motivation": "The paper aims to address the limitation of fixed perturbation budgets in adversarial training, which fail to account for instance-specific robustness characteristics. Current adaptive methods often rely on heuristic or static approximations of data robustness.", "method": "DES integrates three key factors to dynamically adjust the perturbation budget: (1) distance to the decision boundary, (2) prediction confidence, and (3) model uncertainty. These factors are combined into a unified scheduling strategy to guide more effective adversarial learning.", "result": "Experiments on CIFAR-10 and CIFAR-100 show that DES consistently improves both adversarial robustness and standard accuracy compared to fixed-epsilon baselines and prior adaptive methods.", "conclusion": "The paper provides theoretical insights into the stability and convergence of the scheduling policy, opening new avenues for instance-aware, data-driven adversarial training methods."}}
{"id": "2506.04277", "pdf": "https://arxiv.org/pdf/2506.04277", "abs": "https://arxiv.org/abs/2506.04277", "authors": ["Yi Lu", "Jiawang Cao", "Yongliang Wu", "Bozheng Li", "Licheng Tang", "Yangguang Ji", "Chong Wu", "Jay Wu", "Wenbo Zhu"], "title": "RSVP: Reasoning Segmentation via Visual Prompting and Multi-modal Chain-of-Thought", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted as ACL 2025 Main", "summary": "Multi-modal Large Language Models (MLLMs) have demonstrated remarkable\nreasoning capability while lack explicit mechanisms for visual grounding and\nsegmentation, creating a gap between cognitive reasoning and visual perception.\nTo bridge this gap, we introduce Reasoning Segmentation via Visual Prompting\n(RSVP), a novel framework that unifies multi-step multimodal reasoning with\ngrounded visual understanding. RSVP is a two-stage structuralized framework\nthat integrates reasoning-driven localization with segmentation refinement. In\nthe reasoning stage, RSVP employs multimodal chain-of-thought visual prompts to\nhelp MLLMs understand queries and infer targets, generating interpretable\nregion proposals that enhance visual grounding. In segmentation stage, RSVP\nrefines these proposals with a Vision-Language Segmentation Module (VLSM),\nseamlessly integrates textual and visual cues to produce precise segmentation\nmasks. By explicitly modelling the interaction between multimodal reasoning and\nsegmentation, RSVP introduces a new paradigm for interpretable reasoning\nsegmentation. It exploits MLLMs' inherent localization capabilities, enabling\nthe models to not only reason about objects but also generate structured visual\nrepresentations. Our extensive experiments demonstrate that RSVP achieves\nstate-of-the-art performance, surpasses state-of-the-art methods by up to +6.5\ngIoU and +9.2 cIoU on ReasonSeg, and achieves 49.7 mAP on SegInW under\nzero-shot settings. These results validate RSVP as an effective and scalable\nframework for integrating cognitive reasoning with structured visual\nunderstanding.", "AI": {"tldr": "A novel framework RSVP that integrates multi-step multimodal reasoning with grounded visual understanding using visual prompting and segmentation refinement, achieving state-of-the-art performance in reasoning segmentation tasks.", "motivation": "To bridge the gap between cognitive reasoning and visual perception in multi-modal large language models (MLLMs) by introducing explicit mechanisms for visual grounding and segmentation.", "method": "RSVP consists of a two-stage framework: 1) a reasoning stage that uses multimodal chain-of-thought visual prompts to generate interpretable region proposals, and 2) a segmentation stage that refines these proposals using a Vision-Language Segmentation Module (VLSM) to produce precise segmentation masks.", "result": "RSVP achieves state-of-the-art performance on ReasonSeg and SegInW datasets, surpassing existing methods by up to +6.5 gIoU and +9.2 cIoU on ReasonSeg, and achieving 49.7 mAP on SegInW under zero-shot settings.", "conclusion": "RSVP introduces a new paradigm for interpretable reasoning segmentation by explicitly modeling the interaction between multimodal reasoning and segmentation, leveraging MLLMs' localization capabilities to enhance visual understanding."}}
{"id": "2506.04280", "pdf": "https://arxiv.org/pdf/2506.04280", "abs": "https://arxiv.org/abs/2506.04280", "authors": ["Ziming Cheng", "Binrui Xu", "Lisheng Gong", "Zuhe Song", "Tianshuo Zhou", "Shiqi Zhong", "Siyu Ren", "Mingxiang Chen", "Xiangchao Meng", "Yuxin Zhang", "Yanlin Li", "Lei Ren", "Wei Chen", "Zhiyuan Huang", "Mingjie Zhan", "Xiaojie Wang", "Fangxiang Feng"], "title": "Evaluating MLLMs with Multimodal Multi-image Reasoning Benchmark", "categories": ["cs.CV", "cs.AI", "68T50", "I.2.7"], "comment": "18 pages", "summary": "With enhanced capabilities and widespread applications, Multimodal Large\nLanguage Models (MLLMs) are increasingly required to process and reason over\nmultiple images simultaneously. However, existing MLLM benchmarks focus either\non single-image visual reasoning or on multi-image understanding tasks with\nonly final-answer evaluation, leaving the reasoning capabilities of MLLMs over\nmulti-image inputs largely underexplored. To address this gap, we introduce the\n$\\textbf{Multimodal Multi-image Reasoning Benchmark (MMRB)}$, the first\nbenchmark designed to evaluate structured visual reasoning across multiple\nimages. MMRB comprises $\\textbf{92 sub-tasks}$ covering spatial, temporal, and\nsemantic reasoning, with multi-solution, CoT-style annotations generated by\nGPT-4o and refined by human experts. A derivative subset is designed to\nevaluate multimodal reward models in multi-image scenarios. To support fast and\nscalable evaluation, we propose a sentence-level matching framework using\nopen-source LLMs. Extensive baseline experiments on $\\textbf{40 MLLMs}$,\nincluding 9 reasoning-specific models and 8 reward models, demonstrate that\nopen-source MLLMs still lag significantly behind commercial MLLMs in\nmulti-image reasoning tasks. Furthermore, current multimodal reward models are\nnearly incapable of handling multi-image reward ranking tasks.", "AI": {"tldr": "The paper introduces MMRB, a benchmark for evaluating MLLMs' reasoning over multiple images, and shows that open-source MLLMs and reward models perform poorly in these tasks compared to commercial models.", "motivation": "The motivation is to address the lack of benchmarks that evaluate the reasoning capabilities of MLLMs over multiple images. Existing benchmarks focus on single-image visual reasoning or final-answer evaluation, which does not fully capture the reasoning abilities of MLLMs in multi-image scenarios.", "method": "The authors introduce the Multimodal Multi-image Reasoning Benchmark (MMRB), a new benchmark for evaluating MLLMs' ability to reason over multiple images. MMRB consists of 92 sub-tasks that assess spatial, temporal, and semantic reasoning, with annotations generated by GPT-4 and refined by human experts. They also propose a sentence-level matching framework for scalable evaluation and conduct extensive experiments on 40 MLLMs, including reasoning-specific models and reward models.", "result": "Extensive experiments reveal that open-source MLLMs perform poorly compared to commercial MLLMs in multi-image reasoning tasks. Multimodal reward models show minimal effectiveness in handling multi-image reward ranking tasks.", "conclusion": "The results show that open-source MLLMs significantly lag behind commercial MLLMs in multi-image reasoning tasks. Additionally, current multimodal reward models struggle with multi-image reward ranking tasks."}}
{"id": "2506.04351", "pdf": "https://arxiv.org/pdf/2506.04351", "abs": "https://arxiv.org/abs/2506.04351", "authors": ["Maksym Ivashechkin", "Oscar Mendez", "Richard Bowden"], "title": "HuGeDiff: 3D Human Generation via Diffusion with Gaussian Splatting", "categories": ["cs.CV"], "comment": null, "summary": "3D human generation is an important problem with a wide range of applications\nin computer vision and graphics. Despite recent progress in generative AI such\nas diffusion models or rendering methods like Neural Radiance Fields or\nGaussian Splatting, controlling the generation of accurate 3D humans from text\nprompts remains an open challenge. Current methods struggle with fine detail,\naccurate rendering of hands and faces, human realism, and controlability over\nappearance. The lack of diversity, realism, and annotation in human image data\nalso remains a challenge, hindering the development of a foundational 3D human\nmodel. We present a weakly supervised pipeline that tries to address these\nchallenges. In the first step, we generate a photorealistic human image dataset\nwith controllable attributes such as appearance, race, gender, etc using a\nstate-of-the-art image diffusion model. Next, we propose an efficient mapping\napproach from image features to 3D point clouds using a transformer-based\narchitecture. Finally, we close the loop by training a point-cloud diffusion\nmodel that is conditioned on the same text prompts used to generate the\noriginal samples. We demonstrate orders-of-magnitude speed-ups in 3D human\ngeneration compared to the state-of-the-art approaches, along with\nsignificantly improved text-prompt alignment, realism, and rendering quality.\nWe will make the code and dataset available.", "AI": {"tldr": "A weakly supervised pipeline using image diffusion, feature mapping, and point-cloud diffusion is proposed to generate 3D humans from text prompts, achieving significant improvements in speed, realism, and text-prompt alignment.", "motivation": "Current methods for generating 3D humans from text prompts struggle with fine detail, accurate rendering of hands and faces, human realism, and controllability over appearance. The lack of diversity, realism, and annotation in human image data further hinders the development of a foundational 3D human model.", "method": "The paper introduces a weakly supervised pipeline that consists of three key steps to generate 3D humans from text prompts. First, a state-of-the-art image diffusion model is used to generate a dataset of photorealistic human images with controllable attributes. Second, a transformer-based architecture is proposed to efficiently map image features to 3D point clouds. Finally, a point-cloud diffusion model is trained, conditioned on the same text prompts, to generate 3D humans.", "result": "The proposed method achieves orders-of-magnitude speed-ups in 3D human generation compared to existing approaches, while also improving text-prompt alignment, realism, and rendering quality.", "conclusion": "The paper addresses the challenges of generating accurate and realistic 3D humans from text prompts by introducing a novel weakly supervised pipeline. The method significantly improves the speed, text-prompt alignment, realism, and rendering quality of 3D human generation. The authors will make the code and dataset publicly available."}}
{"id": "2506.04244", "pdf": "https://arxiv.org/pdf/2506.04244", "abs": "https://arxiv.org/abs/2506.04244", "authors": ["Farzad Farhadzadeh", "Debasmit Das", "Shubhankar Borse", "Fatih Porikli"], "title": "Zero-Shot Adaptation of Parameter-Efficient Fine-Tuning in Diffusion Models", "categories": ["cs.AI"], "comment": "ICML 2025", "summary": "We introduce ProLoRA, enabling zero-shot adaptation of parameter-efficient\nfine-tuning in text-to-image diffusion models. ProLoRA transfers pre-trained\nlow-rank adjustments (e.g., LoRA) from a source to a target model without\nadditional training data. This overcomes the limitations of traditional methods\nthat require retraining when switching base models, often challenging due to\ndata constraints. ProLoRA achieves this via projection of source adjustments\ninto the target model's weight space, leveraging subspace and null space\nsimilarities and selectively targeting aligned layers. Evaluations on\nestablished text-to-image models demonstrate successful knowledge transfer and\ncomparable performance without retraining.", "AI": {"tldr": "ProLoRA enables zero-shot adaptation of parameter-efficient fine-tuning in text-to-image models by transferring pre-trained low-rank adjustments without additional data, achieving comparable performance to models requiring retraining.", "motivation": "To overcome the limitations of traditional methods that require retraining with additional data when switching base models, which can be challenging due to data constraints.", "method": "ProLoRA transfers pre-trained low-rank adjustments (e.g., LoRA) from a source to a target model by projecting the source adjustments into the target model's weight space, leveraging subspace and null space similarities, and selectively targeting aligned layers.", "result": "Evaluations on established text-to-image models demonstrate successful knowledge transfer and comparable performance without retraining.", "conclusion": "ProLoRA effectively facilitates zero-shot adaptation of parameter-efficient fine-tuning in text-to-image models, making it a valuable tool for model switching without the need for additional training data."}}
{"id": "2506.04656", "pdf": "https://arxiv.org/pdf/2506.04656", "abs": "https://arxiv.org/abs/2506.04656", "authors": ["Qian Hui", "Sidney I. Resnick", "Tiandong Wang"], "title": "Classification of Extremal Dependence in Financial Markets via Bootstrap Inference", "categories": ["math.ST", "stat.TH"], "comment": null, "summary": "Accurately identifying the extremal dependence structure in multivariate\nheavy-tailed data is a fundamental yet challenging task, particularly in\nfinancial applications. Following a recently proposed bootstrap-based testing\nprocedure, we apply the methodology to absolute log returns of U.S. S&P 500 and\nChinese A-share stocks over a time period well before the U.S. election in\n2024. The procedure reveals more isolated clustering of dependent assets in the\nU.S. economy compared with China which exhibits different characteristics and a\nmore interconnected pattern of extremal dependence. Cross-market analysis\nidentifies strong extremal linkages in sectors such as materials, consumer\nstaples and consumer discretionary, highlighting the effectiveness of the\ntesting procedure for large-scale empirical applications.", "AI": {"tldr": "The paper uses a bootstrap-based method to analyze the extremal dependence in U.S. and Chinese stock markets, finding more isolated clustering in the U.S. and more interconnected patterns in China.", "motivation": "The motivation is to accurately identify the extremal dependence structure in multivariate heavy-tailed data, which is crucial for financial applications and risk management.", "method": "The paper employs a bootstrap-based testing procedure to analyze the extremal dependence structure in multivariate heavy-tailed data, specifically focusing on the absolute log returns of U.S. S&P 500 and Chinese A-share stocks.", "result": "The analysis shows more isolated clustering of dependent assets in the U.S. compared to China, which exhibits a more interconnected pattern. Strong extremal linkages are identified in sectors like materials, consumer staples, and consumer discretionary.", "conclusion": "The testing procedure is effective for large-scale empirical applications, revealing distinct patterns of extremal dependence between the U.S. and Chinese markets."}}
{"id": "2506.04344", "pdf": "https://arxiv.org/pdf/2506.04344", "abs": "https://arxiv.org/abs/2506.04344", "authors": ["Caojin Zhang", "Qiang Zhang", "Ke Li", "Sai Vidyaranya Nuthalapati", "Benyu Zhang", "Jason Liu", "Serena Li", "Lizhu Zhang", "Xiangjun Fan"], "title": "GEM: Empowering LLM for both Embedding Generation and Language Understanding", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Large decoder-only language models (LLMs) have achieved remarkable success in\ngeneration and reasoning tasks, where they generate text responses given\ninstructions. However, many applications, e.g., retrieval augmented generation\n(RAG), still rely on separate embedding models to generate text embeddings,\nwhich can complicate the system and introduce discrepancies in understanding of\nthe query between the embedding model and LLMs. To address this limitation, we\npropose a simple self-supervised approach, Generative Embedding large language\nModel (GEM), that enables any large decoder-only LLM to generate high-quality\ntext embeddings while maintaining its original text generation and reasoning\ncapabilities. Our method inserts new special token(s) into a text body, and\ngenerates summarization embedding of the text by manipulating the attention\nmask. This method could be easily integrated into post-training or fine tuning\nstages of any existing LLMs. We demonstrate the effectiveness of our approach\nby applying it to two popular LLM families, ranging from 1B to 8B parameters,\nand evaluating the transformed models on both text embedding benchmarks (MTEB)\nand NLP benchmarks (MMLU). The results show that our proposed method\nsignificantly improves the original LLMs on MTEB while having a minimal impact\non MMLU. Our strong results indicate that our approach can empower LLMs with\nstate-of-the-art text embedding capabilities while maintaining their original\nNLP performance", "AI": {"tldr": "The paper proposes a self-supervised method called Generative Embedding large language Model (GEM) that enables large decoder-only LLMs to generate high-quality text embeddings while retaining their original capabilities.", "motivation": "The motivation is to address the limitation of using separate embedding models in applications like RAG, which can complicate the system and introduce discrepancies between the embedding model and LLMs.", "method": "The method involves inserting special tokens into the text and manipulating the attention mask to generate summarization embeddings. This can be integrated into post-training or fine-tuning stages of existing LLMs.", "result": "The approach significantly improves the performance of LLMs on text embedding benchmarks (MTEB) while having a minimal impact on NLP benchmarks (MMLU).", "conclusion": "GEM empowers LLMs with state-of-the-art text embedding capabilities while maintaining their original performance."}}
{"id": "2506.04353", "pdf": "https://arxiv.org/pdf/2506.04353", "abs": "https://arxiv.org/abs/2506.04353", "authors": ["Ankit Pal", "Jung-Oh Lee", "Xiaoman Zhang", "Malaikannan Sankarasubbu", "Seunghyeon Roh", "Won Jung Kim", "Meesun Lee", "Pranav Rajpurkar"], "title": "ReXVQA: A Large-scale Visual Question Answering Benchmark for Generalist Chest X-ray Understanding", "categories": ["cs.CV", "cs.AI", "cs.CE", "cs.CL", "cs.LG"], "comment": null, "summary": "We present ReXVQA, the largest and most comprehensive benchmark for visual\nquestion answering (VQA) in chest radiology, comprising approximately 696,000\nquestions paired with 160,000 chest X-rays studies across training, validation,\nand test sets. Unlike prior efforts that rely heavily on template based\nqueries, ReXVQA introduces a diverse and clinically authentic task suite\nreflecting five core radiological reasoning skills: presence assessment,\nlocation analysis, negation detection, differential diagnosis, and geometric\nreasoning. We evaluate eight state-of-the-art multimodal large language models,\nincluding MedGemma-4B-it, Qwen2.5-VL, Janus-Pro-7B, and Eagle2-9B. The\nbest-performing model (MedGemma) achieves 83.24% overall accuracy. To bridge\nthe gap between AI performance and clinical expertise, we conducted a\ncomprehensive human reader study involving 3 radiology residents on 200\nrandomly sampled cases. Our evaluation demonstrates that MedGemma achieved\nsuperior performance (83.84% accuracy) compared to human readers (best\nradiology resident: 77.27%), representing a significant milestone where AI\nperformance exceeds expert human evaluation on chest X-ray interpretation. The\nreader study reveals distinct performance patterns between AI models and human\nexperts, with strong inter-reader agreement among radiologists while showing\nmore variable agreement patterns between human readers and AI models. ReXVQA\nestablishes a new standard for evaluating generalist radiological AI systems,\noffering public leaderboards, fine-grained evaluation splits, structured\nexplanations, and category-level breakdowns. This benchmark lays the foundation\nfor next-generation AI systems capable of mimicking expert-level clinical\nreasoning beyond narrow pathology classification. Our dataset will be\nopen-sourced at https://huggingface.co/datasets/rajpurkarlab/ReXVQA", "AI": {"tldr": "ReXVQA is a new, large-scale benchmark for VQA in chest radiology, evaluating AI models' performance on clinically relevant tasks and demonstrating superior AI accuracy compared to human radiology residents.", "motivation": "To create a comprehensive benchmark for evaluating AI performance in VQA for chest radiology, focusing on clinically relevant tasks and comparison with human experts.", "method": "Developed ReXVQA, a dataset of 696,000 questions and 160,000 chest X-rays, and evaluated 8 state-of-the-art multimodal models on five core radiological reasoning skills.", "result": "The best model (MedGemma) achieved 83.24% overall accuracy, outperforming human radiology residents (77.27% accuracy), and showed distinct performance patterns compared to human experts.", "conclusion": "ReXVQA sets a new standard for evaluating radiological AI systems, with public leaderboards and detailed evaluation metrics, paving the way for AI systems mimicking expert-level clinical reasoning."}}
{"id": "2506.04245", "pdf": "https://arxiv.org/pdf/2506.04245", "abs": "https://arxiv.org/abs/2506.04245", "authors": ["Guangchen Lan", "Huseyin A. Inan", "Sahar Abdelnabi", "Janardhan Kulkarni", "Lukas Wutschitz", "Reza Shokri", "Christopher G. Brinton", "Robert Sim"], "title": "Contextual Integrity in LLMs via Reasoning and Reinforcement Learning", "categories": ["cs.AI", "cs.CL", "cs.LG", "I.2.6; I.2.7"], "comment": null, "summary": "As the era of autonomous agents making decisions on behalf of users unfolds,\nensuring contextual integrity (CI) -- what is the appropriate information to\nshare while carrying out a certain task -- becomes a central question to the\nfield. We posit that CI demands a form of reasoning where the agent needs to\nreason about the context in which it is operating. To test this, we first\nprompt LLMs to reason explicitly about CI when deciding what information to\ndisclose. We then extend this approach by developing a reinforcement learning\n(RL) framework that further instills in models the reasoning necessary to\nachieve CI. Using a synthetic, automatically created, dataset of only $\\sim700$\nexamples but with diverse contexts and information disclosure norms, we show\nthat our method substantially reduces inappropriate information disclosure\nwhile maintaining task performance across multiple model sizes and families.\nImportantly, improvements transfer from this synthetic dataset to established\nCI benchmarks such as PrivacyLens that has human annotations and evaluates\nprivacy leakage of AI assistants in actions and tool calls.", "AI": {"tldr": "The paper introduces a reinforcement learning framework to instill contextual integrity (CI) reasoning in AI agents, reducing inappropriate information disclosure while maintaining task performance.", "motivation": "With the rise of autonomous agents, ensuring that they make contextually appropriate decisions about information disclosure is crucial. The paper aims to address this by developing methods to train AI agents to reason about CI.", "method": "The authors first prompt large language models (LLMs) to reason explicitly about CI. They then extend this approach by developing a reinforcement learning (RL) framework that further trains the models to achieve CI. The training uses a synthetic dataset of about 700 diverse examples.", "result": "The method significantly reduces inappropriate information disclosure while maintaining task performance across different model sizes and families. The improvements also transfer to established CI benchmarks like PrivacyLens, which evaluates privacy leakage in AI assistants.", "conclusion": "The paper demonstrates that the proposed RL framework effectively instills CI reasoning in AI agents, improving their ability to make contextually appropriate decisions about information disclosure."}}
{"id": "2506.04825", "pdf": "https://arxiv.org/pdf/2506.04825", "abs": "https://arxiv.org/abs/2506.04825", "authors": ["Sebastian Fuchs", "Carsten Limbach"], "title": "A dimension reduction for extreme types of directed dependence", "categories": ["math.ST", "stat.TH"], "comment": "14 pages, 7 figures", "summary": "In recent years, a variety of novel measures of dependence have been\nintroduced being capable of characterizing diverse types of directed\ndependence, hence diverse types of how a number of predictor variables\n$\\mathbf{X} = (X_1, \\dots, X_p)$, $p \\in \\mathbb{N}$, may affect a response\nvariable $Y$. This includes perfect dependence of $Y$ on $\\mathbf{X}$ and\nindependence between $\\mathbf{X}$ and $Y$, but also less well-known concepts\nsuch as zero-explainability, stochastic comparability and complete separation.\nCertain such measures offer a representation in terms of the Markov product\n$(Y,Y')$, with $Y'$ being a conditionally independent copy of $Y$ given\n$\\mathbf{X}$. This dimension reduction principle allows these measures to be\nestimated via the powerful nearest neighbor based estimation principle\nintroduced in [4]. To achieve a deeper insight into the dimension reduction\nprinciple, this paper aims at translating the extreme variants of directed\ndependence, typically formulated in terms of the random vector\n$(\\mathbf{X},Y)$, into the Markov product $(Y,Y')$.", "AI": {"tldr": "This paper translates extreme variants of directed dependence, typically formulated for random vector (X,Y), into the Markov product (Y,Y') to better understand the dimension reduction principle.", "motivation": "To gain deeper insight into the dimension reduction principle used in dependence measures, translating extreme forms of directed dependence into Markov product representation is necessary.", "method": "The paper reformulates extreme variants of directed dependence in terms of the Markov product (Y,Y'), where Y' is a conditionally independent copy of Y given X, to facilitate estimation via nearest neighbor methods.", "result": "The translation into the Markov product representation provides a clearer understanding of the dimension reduction principle and its application in estimating various dependence measures.", "conclusion": "This translation enhances the theoretical foundation for using the dimension reduction principle and nearest neighbor methods to estimate complex dependence measures between predictor variables and a response variable."}}
{"id": "2506.04364", "pdf": "https://arxiv.org/pdf/2506.04364", "abs": "https://arxiv.org/abs/2506.04364", "authors": ["Zheng-Xin Yong", "Vineel Pratap", "Michael Auli", "Jean Maillard"], "title": "Effects of Speaker Count, Duration, and Accent Diversity on Zero-Shot Accent Robustness in Low-Resource ASR", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": "Accepted to INTERSPEECH 2025", "summary": "To build an automatic speech recognition (ASR) system that can serve everyone\nin the world, the ASR needs to be robust to a wide range of accents including\nunseen accents. We systematically study how three different variables in\ntraining data -- the number of speakers, the audio duration per each individual\nspeaker, and the diversity of accents -- affect ASR robustness towards unseen\naccents in a low-resource training regime. We observe that for a fixed number\nof ASR training hours, it is more beneficial to increase the number of speakers\n(which means each speaker contributes less) than the number of hours\ncontributed per speaker. We also observe that more speakers enables ASR\nperformance gains from scaling number of hours. Surprisingly, we observe\nminimal benefits to prioritizing speakers with different accents when the\nnumber of speakers is controlled. Our work suggests that practitioners should\nprioritize increasing the speaker count in ASR training data composition for\nnew languages.", "AI": {"tldr": "This paper studies the impact of training data variables (number of speakers, audio duration per speaker, and accent diversity) on ASR robustness to unseen accents, suggesting increasing the number of speakers as the most beneficial approach.", "motivation": "The motivation is to improve ASR robustness to a wide range of accents, including unseen ones, in low-resource training scenarios.", "method": "The study systematically varies the number of speakers, the audio duration per speaker, and the diversity of accents in the training data to evaluate their impact on ASR performance with unseen accents.", "result": "Increasing the number of speakers is more beneficial than increasing the audio duration per speaker or prioritizing accent diversity. More speakers also enable greater performance gains from increasing training hours.", "conclusion": "Practitioners should prioritize increasing the number of speakers in ASR training data for new languages to enhance robustness to unseen accents."}}
{"id": "2506.04363", "pdf": "https://arxiv.org/pdf/2506.04363", "abs": "https://arxiv.org/abs/2506.04363", "authors": ["Delong Chen", "Willy Chung", "Yejin Bang", "Ziwei Ji", "Pascale Fung"], "title": "WorldPrediction: A Benchmark for High-level World Modeling and Long-horizon Procedural Planning", "categories": ["cs.CV"], "comment": null, "summary": "Humans are known to have an internal \"world model\" that enables us to carry\nout action planning based on world states. AI agents need to have such a world\nmodel for action planning as well. It is not clear how current AI models,\nespecially generative models, are able to learn such world models and carry out\nprocedural planning in diverse environments. We introduce WorldPrediction, a\nvideo-based benchmark for evaluating world modeling and procedural planning\ncapabilities of different AI models. In contrast to prior benchmarks that focus\nprimarily on low-level world modeling and robotic motion planning,\nWorldPrediction is the first benchmark that emphasizes actions with temporal\nand semantic abstraction. Given initial and final world states, the task is to\ndistinguish the proper action (WorldPrediction-WM) or the properly ordered\nsequence of actions (WorldPrediction-PP) from a set of counterfactual\ndistractors. This discriminative task setup enable us to evaluate different\ntypes of world models and planners and realize a thorough comparison across\ndifferent hypothesis. The benchmark represents states and actions using visual\nobservations. In order to prevent models from exploiting low-level continuity\ncues in background scenes, we provide \"action equivalents\" - identical actions\nobserved in different contexts - as candidates for selection. This benchmark is\ngrounded in a formal framework of partially observable semi-MDP, ensuring\nbetter reliability and robustness of the evaluation. We conduct extensive human\nfiltering and validation on our benchmark and show that current frontier models\nbarely achieve 57% accuracy on WorldPrediction-WM and 38% on WorldPrediction-PP\nwhereas humans are able to solve both tasks perfectly.", "AI": {"tldr": "This study introduces WorldPrediction, a video-based benchmark to evaluate AI models' world modeling and procedural planning skills, emphasizing temporal and semantic abstraction. It assesses the models' ability to distinguish correct actions or sequences from distractors using visual observations, with a formal framework for reliability and robustness.", "motivation": "The motivation is to address the gap in current AI models' ability to learn internal world models for action planning, particularly in diverse environments, and to provide a more comprehensive evaluation framework that goes beyond low-level world modeling and robotic motion planning.", "method": "The method involves creating a video-based benchmark called WorldPrediction, which presents AI models with initial and final world states and asks them to choose the correct action or sequence of actions from a set of options, including counterfactual distractors. The benchmark uses visual observations and 'action equivalents' to prevent reliance on low-level cues.", "result": "Current state-of-the-art models achieve only 57% accuracy on the WorldPrediction-WM task (distinguishing proper actions) and 38% on the WorldPrediction-PP task (ordering sequences of actions), while humans can solve both tasks perfectly.", "conclusion": "The benchmark highlights the limitations of current AI models in performing complex procedural planning and world modeling tasks, and provides a new tool for researchers to evaluate and improve these capabilities in AI systems."}}
{"id": "2506.04251", "pdf": "https://arxiv.org/pdf/2506.04251", "abs": "https://arxiv.org/abs/2506.04251", "authors": ["Zhengyang Li"], "title": "Language-Guided Multi-Agent Learning in Simulations: A Unified Framework and Evaluation", "categories": ["cs.AI", "cs.LG", "cs.MA"], "comment": null, "summary": "This paper introduces LLM-MARL, a unified framework that incorporates large\nlanguage models (LLMs) into multi-agent reinforcement learning (MARL) to\nenhance coordination, communication, and generalization in simulated game\nenvironments. The framework features three modular components of Coordinator,\nCommunicator, and Memory, which dynamically generate subgoals, facilitate\nsymbolic inter-agent messaging, and support episodic recall. Training combines\nPPO with a language-conditioned loss and LLM query gating. LLM-MARL is\nevaluated in Google Research Football, MAgent Battle, and StarCraft II. Results\nshow consistent improvements over MAPPO and QMIX in win rate, coordination\nscore, and zero-shot generalization. Ablation studies demonstrate that subgoal\ngeneration and language-based messaging each contribute significantly to\nperformance gains. Qualitative analysis reveals emergent behaviors such as role\nspecialization and communication-driven tactics. By bridging language modeling\nand policy learning, this work contributes to the design of intelligent,\ncooperative agents in interactive simulations. It offers a path forward for\nleveraging LLMs in multi-agent systems used for training, games, and human-AI\ncollaboration.", "AI": {"tldr": "Introduces LLM-MARL, a framework integrating large language models with multi-agent reinforcement learning to improve coordination, communication, and generalization in game environments, showing significant performance gains.", "motivation": "To enhance coordination, communication, and generalization in multi-agent systems by leveraging the capabilities of large language models.", "method": "The LLM-MARL framework includes Coordinator, Communicator, and Memory components, using PPO with a language-conditioned loss and LLM query gating for training.", "result": "Demonstrates consistent improvements over baseline methods in win rate, coordination score, and zero-shot generalization across multiple game environments.", "conclusion": "Contributes to the design of intelligent, cooperative agents in interactive simulations and opens avenues for leveraging LLMs in multi-agent systems for training, games, and human-AI collaboration."}}
{"id": "2506.04878", "pdf": "https://arxiv.org/pdf/2506.04878", "abs": "https://arxiv.org/abs/2506.04878", "authors": ["Iosif Lytras", "Sotirios Sabanis", "Ying Zhang"], "title": "kTULA: A Langevin sampling algorithm with improved KL bounds under super-linear log-gradients", "categories": ["math.ST", "cs.LG", "math.PR", "stat.ML", "stat.TH"], "comment": null, "summary": "Motivated by applications in deep learning, where the global Lipschitz\ncontinuity condition is often not satisfied, we examine the problem of sampling\nfrom distributions with super-linearly growing log-gradients. We propose a\nnovel tamed Langevin dynamics-based algorithm, called kTULA, to solve the\naforementioned sampling problem, and provide a theoretical guarantee for its\nperformance. More precisely, we establish a non-asymptotic convergence bound in\nKullback-Leibler (KL) divergence with the best-known rate of convergence equal\nto $2-\\overline{\\epsilon}$, $\\overline{\\epsilon}>0$, which significantly\nimproves relevant results in existing literature. This enables us to obtain an\nimproved non-asymptotic error bound in Wasserstein-2 distance, which can be\nused to further derive a non-asymptotic guarantee for kTULA to solve the\nassociated optimization problems. To illustrate the applicability of kTULA, we\napply the proposed algorithm to the problem of sampling from a high-dimensional\ndouble-well potential distribution and to an optimization problem involving a\nneural network. We show that our main results can be used to provide\ntheoretical guarantees for the performance of kTULA.", "AI": {"tldr": "This paper addresses the challenge of sampling from distributions with super-linearly growing log-gradients in deep learning, proposing a novel algorithm called kTULA with improved convergence rates in KL divergence and Wasserstein-2 distance.", "motivation": "The global Lipschitz continuity condition is often not satisfied in deep learning, leading to the need for efficient sampling methods for distributions with super-linearly growing log-gradients.", "method": "The authors propose kTULA, a tamed Langevin dynamics-based algorithm, and establish a non-asymptotic convergence bound in KL divergence with a rate of 2-\u03b5 (\u03b5 > 0). They also derive an improved error bound in Wasserstein-2 distance.", "result": "kTULA achieves the best-known convergence rate in KL divergence and provides an improved error bound in Wasserstein-2 distance, which can be used to give theoretical guarantees for solving associated optimization problems.", "conclusion": "The proposed kTULA algorithm is applied to sampling from a high-dimensional double-well potential distribution and to an optimization problem involving a neural network, demonstrating its effectiveness and providing theoretical guarantees for its performance."}}
{"id": "2506.04373", "pdf": "https://arxiv.org/pdf/2506.04373", "abs": "https://arxiv.org/abs/2506.04373", "authors": ["Matthieu Tehenan", "Vikram Natarajan", "Jonathan Michala", "Milton Lin", "Juri Opitz"], "title": "Mechanistic Decomposition of Sentence Representations", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Sentence embeddings are central to modern NLP and AI systems, yet little is\nknown about their internal structure. While we can compare these embeddings\nusing measures such as cosine similarity, the contributing features are not\nhuman-interpretable, and the content of an embedding seems untraceable, as it\nis masked by complex neural transformations and a final pooling operation that\ncombines individual token embeddings. To alleviate this issue, we propose a new\nmethod to mechanistically decompose sentence embeddings into interpretable\ncomponents, by using dictionary learning on token-level representations. We\nanalyze how pooling compresses these features into sentence representations,\nand assess the latent features that reside in a sentence embedding. This\nbridges token-level mechanistic interpretability with sentence-level analysis,\nmaking for more transparent and controllable representations. In our studies,\nwe obtain several interesting insights into the inner workings of sentence\nembedding spaces, for instance, that many semantic and syntactic aspects are\nlinearly encoded in the embeddings.", "AI": {"tldr": "The paper proposes a method to make sentence embeddings more interpretable by decomposing them into token-level components using dictionary learning.", "motivation": "To address the lack of interpretability in sentence embeddings, which are central to NLP and AI systems.", "method": "Uses dictionary learning on token-level representations to decompose sentence embeddings and analyze the latent features that contribute to the final sentence representation.", "result": "The method reveals that many semantic and syntactic aspects are linearly encoded in sentence embeddings, providing insights into their internal structure.", "conclusion": "The proposed method bridges token-level interpretability with sentence-level analysis, leading to more transparent and controllable sentence representations."}}
{"id": "2506.04365", "pdf": "https://arxiv.org/pdf/2506.04365", "abs": "https://arxiv.org/abs/2506.04365", "authors": ["Liam Salass", "Jerrin Bright", "Amir Nazemi", "Yuhao Chen", "John Zelek", "David Clausi"], "title": "Puck Localization Using Contextual Cues", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Puck detection in ice hockey broadcast videos poses significant challenges\ndue to the puck's small size, frequent occlusions, motion blur, broadcast\nartifacts, and scale inconsistencies due to varying camera zoom and broadcast\ncamera viewpoints. Prior works focus on appearance-based or motion-based cues\nof the puck without explicitly modelling the cues derived from player\nbehaviour. Players consistently turn their bodies and direct their gaze toward\nthe puck. Motivated by this strong contextual cue, we propose Puck Localization\nUsing Contextual Cues (PLUCC), a novel approach for scale-aware and\ncontext-driven single-frame puck detections. PLUCC consists of three\ncomponents: (a) a contextual encoder, which utilizes player orientations and\npositioning as helpful priors; (b) a feature pyramid encoder, which extracts\nmultiscale features from the dual encoders; and (c) a gating decoder that\ncombines latent features with a channel gating mechanism. For evaluation, in\naddition to standard average precision, we propose Rink Space Localization\nError (RSLE), a scale-invariant homography-based metric for removing\nperspective bias from rink space evaluation. The experimental results of PLUCC\non the PuckDataset dataset demonstrated state-of-the-art detection performance,\nsurpassing previous baseline methods by an average precision improvement of\n12.2\\% and RSLE average precision of 25\\%. Our research demonstrates the\ncritical role of contextual understanding in improving puck detection\nperformance, with broad implications for automated sports analysis.", "AI": {"tldr": "The paper presents PLUCC, a novel method for puck detection in ice hockey broadcasts that uses player behavior as contextual cues, achieving state-of-the-art performance.", "motivation": "Puck detection in ice hockey broadcasts is challenging due to the puck's small size, frequent occlusions, motion blur, and varying camera viewpoints. Previous methods focus on appearance or motion cues but do not leverage player behavior, which can provide strong contextual information.", "method": "PLUCC consists of a contextual encoder that uses player orientations and positions, a feature pyramid encoder for multiscale feature extraction, and a gating decoder that combines these features. It evaluates using a scale-invariant metric called Rink Space Localization Error (RSLE).", "result": "PLUCC outperforms previous methods by achieving a 12.2% improvement in average precision and a 25% improvement in RSLE average precision on the PuckDataset.", "conclusion": "The study highlights the importance of contextual cues in improving puck detection, with implications for broader sports analysis applications."}}
{"id": "2506.04252", "pdf": "https://arxiv.org/pdf/2506.04252", "abs": "https://arxiv.org/abs/2506.04252", "authors": ["Yang Zhao", "Chengxiao Dai", "Dusit Niyato", "Chuan Fu Tan", "Keyi Xiang", "Yueyang Wang", "Zhiquan Yeo", "Daren Tan Zong Loong", "Jonathan Low Zhaozhi", "Eugene H. Z. HO"], "title": "A Graph-Retrieval-Augmented Generation Framework Enhances Decision-Making in the Circular Economy", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Large language models (LLMs) hold promise for sustainable manufacturing, but\noften hallucinate industrial codes and emission factors, undermining regulatory\nand investment decisions. We introduce CircuGraphRAG, a retrieval-augmented\ngeneration (RAG) framework that grounds LLMs outputs in a domain-specific\nknowledge graph for the circular economy. This graph connects 117,380\nindustrial and waste entities with classification codes and GWP100 emission\ndata, enabling structured multi-hop reasoning. Natural language queries are\ntranslated into SPARQL and verified subgraphs are retrieved to ensure accuracy\nand traceability. Compared with Standalone LLMs and Naive RAG, CircuGraphRAG\nachieves superior performance in single-hop and multi-hop question answering,\nwith ROUGE-L F1 scores up to 1.0, while baseline scores below 0.08. It also\nimproves efficiency, halving the response time and reducing token usage by 16%\nin representative tasks. CircuGraphRAG provides fact-checked, regulatory-ready\nsupport for circular economy planning, advancing reliable, low-carbon resource\ndecision making.", "AI": {"tldr": "CircuGraphRAG is a retrieval-augmented generation framework that leverages a domain-specific knowledge graph to improve the accuracy and efficiency of large language models in the context of sustainable manufacturing and circular economy planning.", "motivation": "The motivation is to address the issue of large language models hallucinating industrial codes and emission factors, which can affect regulatory and investment decisions in sustainable manufacturing.", "method": "The method involves using a retrieval-augmented generation (RAG) framework that integrates a domain-specific knowledge graph containing industrial and waste entities, classification codes, and GWP100 emission data. Natural language queries are translated into SPARQL to retrieve verified subgraphs, ensuring accuracy and traceability.", "result": "CircuGraphRAG outperforms standalone LLMs and naive RAG in single-hop and multi-hop question answering, achieving ROUGE-L F1 scores of up to 1.0. It also improves efficiency by reducing response time and token usage.", "conclusion": "CircuGraphRAG provides fact-checked, regulatory-ready support for circular economy planning, advancing reliable, low-carbon resource decision making."}}
{"id": "2506.05112", "pdf": "https://arxiv.org/pdf/2506.05112", "abs": "https://arxiv.org/abs/2506.05112", "authors": ["Johann K\u00f6hne", "Fabian Mies"], "title": "At the edge of Donsker's Theorem: Asymptotics of multiscale scan statistics", "categories": ["math.ST", "stat.ME", "stat.TH", "62G10 (Primary), 62M10 (Secondary)"], "comment": "41 pages, 4 figures", "summary": "For nonparametric inference about a function, multiscale testing procedures\nresolve the need for bandwidth selection and achieve asymptotically optimal\ndetection performance against a broad range of alternatives. However, critical\nvalues strongly depend on the noise distribution, and we argue that existing\nmethods are either statistically infeasible, or asymptotically sub-optimal. To\naddress this methodological challenge, we show how to develop a feasible\nmultiscale test via weak convergence arguments, by replacing the additive\nmultiscale penalty with a multiplicative weighting. This new theoretical\nfoundation preserves the optimal detection properties of multiscale tests and\nextends their applicability to nonstationary nonlinear time series via a\ntailored bootstrap scheme. Inference for signal discovery, goodness-of-fit\ntesting of regression functions, and multiple changepoint detection is studied\nin detail, and we apply the new methodology to analyze the April 2025 power\nblackout on the Iberian peninsula. Our methodology is enabled by a novel\nfunctional central limit in H\\\"older spaces with critical modulus of\ncontinuity, where Donsker's theorem fails to hold due to lack of tightness.\nProbabilistically, we discover a novel form of thresholded weak convergence\nthat holds only in the upper support of the distribution.", "AI": {"tldr": "The paper develops a feasible multiscale test method for nonparametric inference, addressing the challenge of critical values dependence on noise distribution, and demonstrates its application to nonstationary nonlinear time series and real-world data like the 2025 Iberian peninsula power blackout.", "motivation": "The motivation is to overcome the limitations of existing multiscale testing procedures, which are either statistically infeasible or asymptotically sub-optimal, and to create a method that is robust to different noise distributions.", "method": "The paper introduces a feasible multiscale test by using weak convergence arguments and replacing the additive multiscale penalty with a multiplicative weighting. This method is applied to nonstationary nonlinear time series through a tailored bootstrap scheme.", "result": "The new methodology achieves optimal detection properties and is applicable to various inference problems such as signal discovery, goodness-of-fit testing, and multiple changepoint detection. The method is demonstrated with an analysis of the April 2025 power blackout on the Iberian peninsula.", "conclusion": "The paper concludes with the development of a novel functional central limit theorem in H\u00f6lder spaces and a new form of thresholded weak convergence, which are key to the success of the proposed multiscale test in handling nonstationary data."}}
{"id": "2506.04381", "pdf": "https://arxiv.org/pdf/2506.04381", "abs": "https://arxiv.org/abs/2506.04381", "authors": ["Neeraj Agrawal", "Saurabh Kumar", "Priyanka Bhatt", "Tanishka Agarwal"], "title": "Hierarchical Text Classification Using Contrastive Learning Informed Path Guided Hierarchy", "categories": ["cs.CL", "cs.LG"], "comment": "arXiv admin note: text overlap with arXiv:2203.03825 by other authors", "summary": "Hierarchical Text Classification (HTC) has recently gained traction given the\nability to handle complex label hierarchy. This has found applications in\ndomains like E- commerce, customer care and medicine industry among other\nreal-world applications. Existing HTC models either encode label hierarchy\nseparately and mix it with text encoding or guide the label hierarchy structure\nin the text encoder. Both approaches capture different characteristics of label\nhierarchy and are complementary to each other. In this paper, we propose a\nHierarchical Text Classification using Contrastive Learning Informed Path\nguided hierarchy (HTC-CLIP), which learns hierarchy-aware text representation\nand text informed path guided hierarchy representation using contrastive\nlearning. During the training of HTC-CLIP, we learn two different sets of class\nprobabilities distributions and during inference, we use the pooled output of\nboth probabilities for each class to get the best of both representations. Our\nresults show that the two previous approaches can be effectively combined into\none architecture to achieve improved performance. Tests on two public benchmark\ndatasets showed an improvement of 0.99 - 2.37% in Macro F1 score using HTC-CLIP\nover the existing state-of-the-art models.", "AI": {"tldr": "Proposes HTC-CLIP, a method combining hierarchy-aware text representation and text-informed path-guided hierarchy using contrastive learning, achieving improved performance on benchmark datasets.", "motivation": "To address the limitations of existing HTC models by combining two complementary approaches to better capture the characteristics of label hierarchy.", "method": "Introduces HTC-CLIP, which uses contrastive learning to learn hierarchy-aware text representation and text-informed path-guided hierarchy representation, and combines two sets of class probability distributions during inference.", "result": "Achieved a 0.99 - 2.37% improvement in Macro F1 score on two public benchmark datasets compared to existing state-of-the-art models.", "conclusion": "The proposed HTC-CLIP effectively combines the strengths of existing approaches, leading to better performance in hierarchical text classification."}}
{"id": "2506.04367", "pdf": "https://arxiv.org/pdf/2506.04367", "abs": "https://arxiv.org/abs/2506.04367", "authors": ["Jubayer Ahmed Bhuiyan Shawon", "Hasan Mahmud", "Kamrul Hasan"], "title": "Fine-Tuning Video Transformers for Word-Level Bangla Sign Language: A Comparative Analysis for Classification Tasks", "categories": ["cs.CV"], "comment": "16 pages, 8 figures, 6 tables", "summary": "Sign Language Recognition (SLR) involves the automatic identification and\nclassification of sign gestures from images or video, converting them into text\nor speech to improve accessibility for the hearing-impaired community. In\nBangladesh, Bangla Sign Language (BdSL) serves as the primary mode of\ncommunication for many individuals with hearing impairments. This study\nfine-tunes state-of-the-art video transformer architectures -- VideoMAE, ViViT,\nand TimeSformer -- on BdSLW60 (arXiv:2402.08635), a small-scale BdSL dataset\nwith 60 frequent signs. We standardized the videos to 30 FPS, resulting in\n9,307 user trial clips. To evaluate scalability and robustness, the models were\nalso fine-tuned on BdSLW401 (arXiv:2503.02360), a large-scale dataset with 401\nsign classes. Additionally, we benchmark performance against public datasets,\nincluding LSA64 and WLASL. Data augmentation techniques such as random\ncropping, horizontal flipping, and short-side scaling were applied to improve\nmodel robustness. To ensure balanced evaluation across folds during model\nselection, we employed 10-fold stratified cross-validation on the training set,\nwhile signer-independent evaluation was carried out using held-out test data\nfrom unseen users U4 and U8. Results show that video transformer models\nsignificantly outperform traditional machine learning and deep learning\napproaches. Performance is influenced by factors such as dataset size, video\nquality, frame distribution, frame rate, and model architecture. Among the\nmodels, the VideoMAE variant (MCG-NJU/videomae-base-finetuned-kinetics)\nachieved the highest accuracies of 95.5% on the frame rate corrected BdSLW60\ndataset and 81.04% on the front-facing signs of BdSLW401 -- demonstrating\nstrong potential for scalable and accurate BdSL recognition.", "AI": {"tldr": "The study fine-tunes video transformer architectures on BdSL datasets, achieving high accuracy in Bangla Sign Language recognition, with VideoMAE outperforming other models.", "motivation": "To improve accessibility for the hearing-impaired community in Bangladesh by fine-tuning state-of-the-art video transformer architectures on BdSL datasets and evaluating their performance on various datasets.", "method": "The study fine-tuned VideoMAE, ViViT, and TimeSformer on BdSLW60 and BdSLW401 datasets, applied data augmentation techniques, and used 10-fold stratified cross-validation for model selection, with signer-independent evaluation on held-out test data.", "result": "Video transformer models significantly outperformed traditional approaches, with VideoMAE achieving the highest accuracies of 95.5% on BdSLW60 and 81.04% on BdSLW401.", "conclusion": "The study demonstrates the strong potential of video transformer models, particularly VideoMAE, for scalable and accurate BdSL recognition, highlighting the importance of dataset size and video quality."}}
{"id": "2506.04253", "pdf": "https://arxiv.org/pdf/2506.04253", "abs": "https://arxiv.org/abs/2506.04253", "authors": ["Tapio Pitk\u00e4ranta", "Leena Pitk\u00e4ranta"], "title": "HADA: Human-AI Agent Decision Alignment Architecture", "categories": ["cs.AI", "cs.AI, cs.SE, cs.MA, cs.CL, cs.LG"], "comment": "18 pages, 4 figures", "summary": "We present HADA (Human-AI Agent Decision Alignment), a protocol- and\nframework agnostic reference architecture that keeps both large language model\n(LLM) agents and legacy algorithms aligned with organizational targets and\nvalues. HADA wraps any algorithm or LLM in role-specific stakeholder agents --\nbusiness, data-science, audit, ethics, and customer -- each exposing\nconversational APIs so that technical and non-technical actors can query,\nsteer, audit, or contest every decision across strategic, tactical, and\nreal-time horizons. Alignment objectives, KPIs, and value constraints are\nexpressed in natural language and are continuously propagated, logged, and\nversioned while thousands of heterogeneous agents run on different\norchestration stacks. A cloud-native proof of concept packages a production\ncredit-scoring model (getLoanDecision) and deploys it on\nDocker/Kubernetes/Python; five scripted retail-bank scenarios show how target\nchanges, parameter tweaks, explanation requests, and ethics triggers flow end\nto end through the architecture. Evaluation followed the Design-Science\nResearch Methodology. Walkthrough observation and log inspection demonstrated\ncomplete coverage of six predefined objectives: every role could invoke\nconversational control, trace KPIs and value constraints, detect and mitigate\nZIP-code bias, and reproduce full decision lineage, independent of the\nunderlying LLM or agent library. Contributions: (1) an open-source HADA\narchitecture, (2) a mid-range design theory for human-AI alignment in\nmulti-agent systems, and (3) empirical evidence that framework-agnostic,\nprotocol-compliant stakeholder agents improve accuracy, transparency, and\nethical compliance in real-world decision pipelines.", "AI": {"tldr": "HADA is a reference architecture that aligns AI and legacy systems with organizational goals and values, demonstrated through a retail banking proof of concept showing improved accuracy, transparency, and ethical compliance.", "motivation": "The motivation is to address the challenge of aligning AI and legacy systems with organizational goals and values, ensuring that decisions are transparent, traceable, and ethically compliant.", "method": "HADA uses role-specific stakeholder agents (business, data-science, audit, ethics, and customer) that expose conversational APIs, allowing stakeholders to query, steer, audit, or contest decisions. The architecture continuously propagates, logs, and versions alignment objectives, KPIs, and value constraints.", "result": "The paper introduces HADA, a reference architecture that aligns both LLMs and legacy algorithms with organizational targets and values across various roles and horizons. It demonstrates the architecture's effectiveness through a cloud-native proof of concept in a retail banking scenario, showing improved accuracy, transparency, and ethical compliance.", "conclusion": "The paper concludes by presenting HADA as an open-source architecture, a mid-range design theory for human-AI alignment in multi-agent systems, and empirical evidence of its effectiveness in improving decision-making processes."}}
{"id": "2506.05113", "pdf": "https://arxiv.org/pdf/2506.05113", "abs": "https://arxiv.org/abs/2506.05113", "authors": ["Anuj Abhishek", "Alexander Katsevich", "James W. Webber"], "title": "Statistical microlocal analysis in two-dimensional X-ray CT", "categories": ["math.ST", "math.FA", "stat.TH"], "comment": "27 pages, 13 figures", "summary": "In many imaging applications it is important to assess how well the edges of\nthe original object, $f$, are resolved in an image, $f^\\text{rec}$,\nreconstructed from the measured data, $g$. In this paper we consider the case\nof image reconstruction in 2D X-ray Computed Tomography (CT). Let $f$ be a\nfunction describing the object being scanned, and $g=Rf + \\eta$ be the Radon\ntransform data in $\\mathbb{R}^2$ corrupted by noise, $\\eta$, and sampled with\nstep size $\\sim\\epsilon$. Conventional microlocal analysis provides conditions\nfor edge detectability based on the scanner geometry in the case of continuous,\nnoiseless data (when $\\eta = 0$), but does not account for noise and finite\nsampling step size. We develop a novel technique called \\emph{Statistical\nMicrolocal Analysis} (SMA), which uses a statistical hypothesis testing\nframework to determine if an image edge (singularity) of $f$ is detectable from\n$f^\\text{rec}$, and we quantify edge detectability using the statistical power\nof the test. Our approach is based on the theory we developed in\n\\cite{AKW2024_1}, which provides a characterization of $f^\\text{rec}$ in local\n$O(\\epsilon)$-size neighborhoods when $\\eta \\neq 0$. We derive a statistical\ntest for the presence and direction of an edge microlocally given the magnitude\nof $\\eta$ and data sampling step size. Using the properties of the null\ndistribution of the test, we quantify the uncertainty of the edge magnitude and\ndirection. We validate our theory using simulations, which show strong\nagreement between our predictions and experimental observations. Our work is\nnot only of practical value, but of theoretical value as well. SMA is a natural\nextension of classical microlocal analysis theory which accounts for practical\nmeasurement imperfections, such as noise and finite step size, at the highest\npossible resolution compatible with the data.", "AI": {"tldr": "The paper introduces Statistical Microlocal Analysis (SMA) to assess edge detectability in 2D X-ray CT images, accounting for noise and finite sampling step size, and validates the method through simulations.", "motivation": "The motivation is to address the limitations of conventional microlocal analysis, which does not account for noise and finite sampling step size in image reconstruction, and to provide a robust method for edge detection in practical imaging scenarios.", "method": "The method involves developing a statistical hypothesis testing framework called Statistical Microlocal Analysis (SMA) to determine if image edges are detectable from reconstructed images. The approach characterizes the reconstructed image in local neighborhoods and quantifies edge detectability using statistical power.", "result": "The method is validated through simulations, showing strong agreement between theoretical predictions and experimental observations.", "conclusion": "The paper concludes that SMA is a valuable extension of classical microlocal analysis, providing a practical and theoretically sound method for assessing edge detectability in 2D X-ray CT images, even in the presence of noise and finite sampling step size."}}
{"id": "2506.04385", "pdf": "https://arxiv.org/pdf/2506.04385", "abs": "https://arxiv.org/abs/2506.04385", "authors": ["Kurt Micallef", "Claudia Borg"], "title": "MELABenchv1: Benchmarking Large Language Models against Smaller Fine-Tuned Models for Low-Resource Maltese NLP", "categories": ["cs.CL", "cs.AI"], "comment": "ACL 2025 Findings Camera-Ready", "summary": "Large Language Models (LLMs) have demonstrated remarkable performance across\nvarious Natural Language Processing (NLP) tasks, largely due to their\ngeneralisability and ability to perform tasks without additional training.\nHowever, their effectiveness for low-resource languages remains limited. In\nthis study, we evaluate the performance of 55 publicly available LLMs on\nMaltese, a low-resource language, using a newly introduced benchmark covering\n11 discriminative and generative tasks. Our experiments highlight that many\nmodels perform poorly, particularly on generative tasks, and that smaller\nfine-tuned models often perform better across all tasks. From our\nmultidimensional analysis, we investigate various factors impacting\nperformance. We conclude that prior exposure to Maltese during pre-training and\ninstruction-tuning emerges as the most important factor. We also examine the\ntrade-offs between fine-tuning and prompting, highlighting that while\nfine-tuning requires a higher initial cost, it yields better performance and\nlower inference costs. Through this work, we aim to highlight the need for more\ninclusive language technologies and recommend that researchers working with\nlow-resource languages consider more \"traditional\" language modelling\napproaches.", "AI": {"tldr": "An evaluation of 55 large language models on Maltese, a low-resource language, reveals that smaller fine-tuned models often outperform larger ones, and prior exposure to Maltese is crucial for performance. Fine-tuning, though costly, results in better and more cost-effective models.", "motivation": "The motivation is to assess the effectiveness of large language models on low-resource languages, specifically Maltese, and to understand the factors that influence their performance.", "method": "The study evaluates 55 publicly available LLMs on a newly introduced benchmark covering 11 discriminative and generative tasks in Maltese, analyzing the impact of factors like model size, fine-tuning, and prior exposure to the language.", "result": "Many models performed poorly, especially on generative tasks, with smaller fine-tuned models often performing better. Prior exposure to Maltese during pre-training and instruction-tuning was the most significant factor for performance.", "conclusion": "The study recommends that researchers working with low-resource languages consider more traditional language modeling approaches, such as fine-tuning, to achieve better performance and lower inference costs. The work also emphasizes the need for more inclusive language technologies."}}
{"id": "2506.04379", "pdf": "https://arxiv.org/pdf/2506.04379", "abs": "https://arxiv.org/abs/2506.04379", "authors": ["Matthew W. Shinkle", "Mark D. Lescroart"], "title": "Visualizing and Controlling Cortical Responses Using Voxel-Weighted Activation Maximization", "categories": ["cs.CV", "cs.AI", "q-bio.NC"], "comment": "Accepted to the Mechanistic Interpretability for Vision (MIV)\n  Workshop at the 2025 Conference on Computer Vision and Pattern Recognition\n  (CVPR) conference", "summary": "Deep neural networks (DNNs) trained on visual tasks develop feature\nrepresentations that resemble those in the human visual system. Although\nDNN-based encoding models can accurately predict brain responses to visual\nstimuli, they offer limited insight into the specific features driving these\nresponses. Here, we demonstrate that activation maximization -- a technique\ndesigned to interpret vision DNNs -- can be applied to DNN-based encoding\nmodels of the human brain. We extract and adaptively downsample activations\nfrom multiple layers of a pretrained Inception V3 network, then use linear\nregression to predict fMRI responses. This yields a full image-computable model\nof brain responses. Next, we apply activation maximization to generate images\noptimized for predicted responses in individual cortical voxels. We find that\nthese images contain visual characteristics that qualitatively correspond with\nknown selectivity and enable exploration of selectivity across the visual\ncortex. We further extend our method to whole regions of interest (ROIs) of the\nbrain and validate its efficacy by presenting these images to human\nparticipants in an fMRI study. We find that the generated images reliably drive\nactivity in targeted regions across both low- and high-level visual areas and\nacross subjects. These results demonstrate that activation maximization can be\nsuccessfully applied to DNN-based encoding models. By addressing key\nlimitations of alternative approaches that require natively generative models,\nour approach enables flexible characterization and modulation of responses\nacross the human visual system.", "AI": {"tldr": "This paper shows that activation maximization, a technique used to interpret deep neural networks, can be applied to DNN-based encoding models of the human brain, generating images that drive activity in specific brain regions and enabling better understanding of the human visual system.", "motivation": "The motivation is to improve the interpretability of DNN-based encoding models of the human visual system, which can predict brain responses to visual stimuli but offer limited insight into the specific features driving these responses.", "method": "The method involves using activation maximization to generate images optimized for predicted fMRI responses in individual cortical voxels and whole brain regions, using a pretrained Inception V3 network and linear regression to predict fMRI responses.", "result": "The generated images reliably drive activity in targeted brain regions across both low- and high-level visual areas and across subjects, demonstrating the effectiveness of using activation maximization for DNN-based encoding models.", "conclusion": "The paper concludes that activation maximization can be successfully applied to DNN-based encoding models, addressing limitations of alternative approaches and enabling flexible characterization and modulation of responses in the human visual system."}}
{"id": "2506.04287", "pdf": "https://arxiv.org/pdf/2506.04287", "abs": "https://arxiv.org/abs/2506.04287", "authors": ["Yongjin Yang", "Sinjae Kang", "Juyong Lee", "Dongjun Lee", "Se-Young Yun", "Kimin Lee"], "title": "Automated Skill Discovery for Language Agents through Exploration and Iterative Feedback", "categories": ["cs.AI", "cs.LG"], "comment": "Preprint, under review", "summary": "Training large language model (LLM) agents to acquire necessary skills and\nperform diverse tasks within an environment is gaining interest as a means to\nenable open-endedness. However, creating the training dataset for their skill\nacquisition faces several challenges. Manual trajectory collection requires\nsignificant human effort. Another approach, where LLMs directly propose tasks\nto learn, is often invalid, as the LLMs lack knowledge of which tasks are\nactually feasible. Moreover, the generated data may not provide a meaningful\nlearning signal, as agents often already perform well on the proposed tasks. To\naddress this, we propose a novel automatic skill discovery framework EXIF for\nLLM-powered agents, designed to improve the feasibility of generated target\nbehaviors while accounting for the agents' capabilities. Our method adopts an\nexploration-first strategy by employing an exploration agent (Alice) to train\nthe target agent (Bob) to learn essential skills in the environment.\nSpecifically, Alice first interacts with the environment to retrospectively\ngenerate a feasible, environment-grounded skill dataset, which is then used to\ntrain Bob. Crucially, we incorporate an iterative feedback loop, where Alice\nevaluates Bob's performance to identify areas for improvement. This feedback\nthen guides Alice's next round of exploration, forming a closed-loop data\ngeneration process. Experiments on Webshop and Crafter demonstrate EXIF's\nability to effectively discover meaningful skills and iteratively expand the\ncapabilities of the trained agent without any human intervention, achieving\nsubstantial performance improvements. Interestingly, we observe that setting\nAlice to the same model as Bob also notably improves performance, demonstrating\nEXIF's potential for building a self-evolving system.", "AI": {"tldr": "EXIF is a novel framework that uses an exploration agent to generate a feasible skill dataset and iteratively train a target agent, improving performance and capabilities in environments like Webshop and Crafter without human intervention.", "motivation": "The motivation is to address the challenges in creating a training dataset for LLM agents, such as the need for significant human effort in manual trajectory collection and the generation of invalid or non-meaningful tasks by LLMs. EXIF aims to improve the feasibility of generated target behaviors while considering the agents' capabilities.", "method": "The method proposed is an automatic skill discovery framework called EXIF for LLM-powered agents. It involves an exploration agent (Alice) that interacts with the environment to generate a feasible, environment-grounded skill dataset, which is used to train the target agent (Bob). The process includes an iterative feedback loop where Alice evaluates Bob's performance to identify areas for improvement, guiding the next round of exploration.", "result": "Experiments on Webshop and Crafter show that EXIF can effectively discover meaningful skills and iteratively expand the capabilities of the trained agent without human intervention, leading to substantial performance improvements. Notably, setting Alice to the same model as Bob also improves performance, suggesting potential for a self-evolving system.", "conclusion": "The EXIF framework demonstrates the ability to automatically discover and iteratively improve skills for LLM-powered agents, enhancing their capabilities in a closed-loop data generation process without human intervention. The potential for a self-evolving system is also highlighted."}}
{"id": "2506.04441", "pdf": "https://arxiv.org/pdf/2506.04441", "abs": "https://arxiv.org/abs/2506.04441", "authors": ["Jose H Guardiola"], "title": "On the Spherical Dirichlet Distribution: Corrections and Results", "categories": ["stat.ME", "math.ST", "stat.TH", "62E10, 62F10"], "comment": "25 pages, 2 figures. This submission corrects and extends a\n  previously published open-access article in Journal of Statistical\n  Distributions and Applications", "summary": "This note corrects a technical error in Guardiola (2020, Journal of\nStatistical Distributions and Applications), presents updated derivations, and\noffers an extended discussion of the properties of the spherical Dirichlet\ndistribution. Today, data mining and gene expressions are at the forefront of\nmodern data analysis. Here we introduce a novel probability distribution that\nis applicable in these fields. This paper develops the proposed\nSpherical-Dirichlet Distribution designed to fit vectors located at the\npositive orthant of the hypersphere, as it is often the case for data in these\nfields, avoiding unnecessary probability mass. Basic properties of the proposed\ndistribution, including normalizing constants and moments are developed.\nRelationships with other distributions are also explored. Estimators based on\nclassical inferential statistics, such as method of moments and maximum\nlikelihood estimators are obtained. Two applications are developed: the first\none uses simulated data, and the second uses a real text mining example. Both\nexamples are fitted using the proposed Spherical-Dirichlet Distribution and\ntheir results are discussed.", "AI": {"tldr": "This paper corrects an error in a previous study, updates derivations, and introduces a Spherical-Dirichlet Distribution for data on the positive orthant of the hypersphere, presenting its properties and applications.", "motivation": "The motivation is to address a technical error in a previous study and to introduce a novel probability distribution, the Spherical-Dirichlet Distribution, which is particularly useful for data in data mining and gene expression analysis.", "method": "The paper develops the Spherical-Dirichlet Distribution, derives its basic properties (normalizing constants and moments), and explores its relationships with other distributions. It also obtains estimators using classical inferential statistics (method of moments and maximum likelihood).", "result": "The paper presents two applications: one with simulated data and another with real text mining data. Both applications are fitted using the Spherical-Dirichlet Distribution, and the results are discussed.", "conclusion": "The Spherical-Dirichlet Distribution is a valuable tool for modeling data on the positive orthant of the hypersphere, particularly in data mining and gene expression analysis. The paper corrects previous errors and provides a comprehensive exploration of the distribution's properties and applications."}}
{"id": "2506.04389", "pdf": "https://arxiv.org/pdf/2506.04389", "abs": "https://arxiv.org/abs/2506.04389", "authors": ["Saurabh Kumar", "Sourav Bansal", "Neeraj Agrawal", "Priyanka Bhatt"], "title": "Building a Few-Shot Cross-Domain Multilingual NLU Model for Customer Care", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Customer care is an essential pillar of the e-commerce shopping experience\nwith companies spending millions of dollars each year, employing automation and\nhuman agents, across geographies (like US, Canada, Mexico, Chile), channels\n(like Chat, Interactive Voice Response (IVR)), and languages (like English,\nSpanish). SOTA pre-trained models like multilingual-BERT, fine-tuned on\nannotated data have shown good performance in downstream tasks relevant to\nCustomer Care. However, model performance is largely subject to the\navailability of sufficient annotated domain-specific data. Cross-domain\navailability of data remains a bottleneck, thus building an intent classifier\nthat generalizes across domains (defined by channel, geography, and language)\nwith only a few annotations, is of great practical value. In this paper, we\npropose an embedder-cum-classifier model architecture which extends\nstate-of-the-art domain-specific models to other domains with only a few\nlabeled samples. We adopt a supervised fine-tuning approach with isotropic\nregularizers to train a domain-specific sentence embedder and a multilingual\nknowledge distillation strategy to generalize this embedder across multiple\ndomains. The trained embedder, further augmented with a simple linear\nclassifier can be deployed for new domains. Experiments on Canada and Mexico\ne-commerce Customer Care dataset with few-shot intent detection show an\nincrease in accuracy by 20-23% against the existing state-of-the-art\npre-trained models.", "AI": {"tldr": "The paper proposes an embedder-cum-classifier model that leverages a few labeled samples and multilingual knowledge distillation to improve intent classification in e-commerce customer care across different domains, achieving a 20-23% accuracy increase over existing methods.", "motivation": "The motivation is to address the challenge of generalizing intent classifiers across different e-commerce domains (e.g., geographies, channels, languages) with limited annotated data, which is a significant bottleneck in practical applications.", "method": "The method involves training a domain-specific sentence embedder using supervised fine-tuning with isotropic regularizers, followed by multilingual knowledge distillation to generalize the embedder across multiple domains. The embedder is then paired with a simple linear classifier for deployment in new domains.", "result": "The experiments on Canada and Mexico e-commerce Customer Care datasets show that the proposed model outperforms existing state-of-the-art pre-trained models by 20-23% in few-shot intent detection tasks.", "conclusion": "The paper concludes that the proposed embedder-cum-classifier model effectively generalizes across different domains with limited labeled data, significantly improving intent classification accuracy in e-commerce customer care."}}
{"id": "2506.04394", "pdf": "https://arxiv.org/pdf/2506.04394", "abs": "https://arxiv.org/abs/2506.04394", "authors": ["Qiuyu Tang", "Bonor Ayambem", "Mooi Choo Chuah", "Aparna Bharati"], "title": "Is Perturbation-Based Image Protection Disruptive to Image Editing?", "categories": ["cs.CV"], "comment": "6 pages, 8 figures, accepted by ICIP 2025", "summary": "The remarkable image generation capabilities of state-of-the-art diffusion\nmodels, such as Stable Diffusion, can also be misused to spread misinformation\nand plagiarize copyrighted materials. To mitigate the potential risks\nassociated with image editing, current image protection methods rely on adding\nimperceptible perturbations to images to obstruct diffusion-based editing. A\nfully successful protection for an image implies that the output of editing\nattempts is an undesirable, noisy image which is completely unrelated to the\nreference image. In our experiments with various perturbation-based image\nprotection methods across multiple domains (natural scene images and artworks)\nand editing tasks (image-to-image generation and style editing), we discover\nthat such protection does not achieve this goal completely. In most scenarios,\ndiffusion-based editing of protected images generates a desirable output image\nwhich adheres precisely to the guidance prompt. Our findings suggest that\nadding noise to images may paradoxically increase their association with given\ntext prompts during the generation process, leading to unintended consequences\nsuch as better resultant edits. Hence, we argue that perturbation-based methods\nmay not provide a sufficient solution for robust image protection against\ndiffusion-based editing.", "AI": {"tldr": "Current image protection methods using imperceptible perturbations do not fully prevent diffusion-based editing, and can sometimes lead to better-edited images, suggesting that perturbation-based methods are insufficient for robust image protection.", "motivation": "To address the misuse of image generation models like Stable Diffusion, which can be used to spread misinformation and plagiarize copyrighted materials, the paper explores the effectiveness of current image protection methods that rely on adding imperceptible perturbations to images to obstruct diffusion-based editing.", "method": "The researchers conducted experiments with various perturbation-based image protection methods across multiple domains (natural scene images and artworks) and editing tasks (image-to-image generation and style editing) to evaluate their effectiveness in preventing diffusion-based editing.", "result": "The experiments revealed that in most scenarios, diffusion-based editing of protected images still generates desirable output images that adhere to the guidance prompts. Furthermore, adding noise to images may paradoxically increase their association with given text prompts during the generation process, leading to better resultant edits.", "conclusion": "The findings suggest that perturbation-based methods are not a sufficient solution for robust image protection against diffusion-based editing, highlighting the need for alternative approaches."}}
{"id": "2506.04374", "pdf": "https://arxiv.org/pdf/2506.04374", "abs": "https://arxiv.org/abs/2506.04374", "authors": ["Jack David Carson", "Amir Reisizadeh"], "title": "A Statistical Physics of Language Model Reasoning", "categories": ["cs.AI"], "comment": null, "summary": "Transformer LMs show emergent reasoning that resists mechanistic\nunderstanding. We offer a statistical physics framework for continuous-time\nchain-of-thought reasoning dynamics. We model sentence-level hidden state\ntrajectories as a stochastic dynamical system on a lower-dimensional manifold.\nThis drift-diffusion system uses latent regime switching to capture diverse\nreasoning phases, including misaligned states or failures. Empirical\ntrajectories (8 models, 7 benchmarks) show a rank-40 projection (balancing\nvariance capture and feasibility) explains ~50% variance. We find four latent\nreasoning regimes. An SLDS model is formulated and validated to capture these\nfeatures. The framework enables low-cost reasoning simulation, offering tools\nto study and predict critical transitions like misaligned states or other LM\nfailures.", "AI": {"tldr": "A statistical physics framework is introduced to model the reasoning dynamics of transformers, using a lower-dimensional manifold to represent hidden state trajectories and an SLDS model to capture latent reasoning regimes, enabling the simulation and prediction of reasoning transitions and failures.", "motivation": "The motivation is to provide a mechanistic understanding of the emergent reasoning processes in transformer language models, which currently resist straightforward explanation.", "method": "The method involves modeling the hidden state trajectories of transformer models as a stochastic dynamical system on a lower-dimensional manifold, using latent regime switching to capture different reasoning phases, and validating the model with empirical data from multiple models and benchmarks.", "result": "The results show that a rank-40 projection explains approximately 50% of the variance in the empirical trajectories, and the model identifies four latent reasoning regimes.", "conclusion": "The framework enables efficient simulation and analysis of reasoning dynamics, providing tools to predict critical transitions and failures in transformer models."}}
{"id": "2506.04445", "pdf": "https://arxiv.org/pdf/2506.04445", "abs": "https://arxiv.org/abs/2506.04445", "authors": ["Mar\u00eda Jaenada", "Juan Manuel Mill\u00e1n", "Leandro Pardo"], "title": "Robust Estimation in Step-Stress Experiments under Exponential Lifetime Distributions", "categories": ["stat.ME", "math.ST", "stat.TH", "62F35", "B.8.1"], "comment": "20 pages (without Appendix), 4 figures, 6 tables", "summary": "Many modern products exhibit high reliability, often resulting in long times\nto failure. Consequently, conducting experiments under normal operating\nconditions may require an impractically long duration to obtain sufficient\nfailure data for reliable statistical inference. As an alternative, accelerated\nlife tests (ALTs) are employed to induce earlier failures and thereby reduce\ntesting time. In step-stress experiments a stress factor that accelerates\nproduct degradation is identified and systematically increased to provoke early\nfailures. The stress level is increased at predetermined time points and\nmaintained constant between these intervals. Failure data observed under\nincreased levels of stress is statistically analyzed, and results are then\nextrapolate to normal operating conditions.\n  Classical estimation methods such analysis rely on the maximum likelihood\nestimator (MLE) which is know to be very efficient, but lack robustness in the\npresence of outlying data. In this work, Minimum Density Power Divergence\nEstimators (MDPDEs) are proposed as a robust alternative, demonstrating an\nappealing compromise between efficiency and robustness. The MDPDE based on\nmixed distributions is developed, and its theoretical properties, including the\nexpression for the asymptotic distribution of the model parameters, are derived\nunder exponential lifetime assumptions. The good performance of the proposed\nmethod is evaluated through simulation studies, and its applicability is\ndemonstrated using real data.", "AI": {"tldr": "The paper proposes using Minimum Density Power Divergence Estimators (MDPDEs) as a robust alternative to the traditional maximum likelihood estimator (MLE) in step-stress accelerated life tests (ALTs) for high-reliability products, demonstrating its efficiency and robustness through simulation and real data analysis.", "motivation": "High-reliability products often require impractically long testing times under normal operating conditions to obtain sufficient failure data. Accelerated life tests (ALTs) and step-stress experiments are used to induce earlier failures, but traditional methods like MLE can be sensitive to outlying data, necessitating a more robust approach.", "method": "The paper introduces MDPDEs, a robust alternative to MLE, for parameter estimation in step-stress ALTs. The method is based on mixed distributions and its theoretical properties, including asymptotic distribution, are derived under exponential lifetime assumptions.", "result": "Simulation studies show that MDPDEs provide a good balance between efficiency and robustness. The method's applicability is further demonstrated using real data, indicating its potential for practical use in reliability testing.", "conclusion": "MDPDEs offer an attractive compromise between efficiency and robustness in step-stress ALTs, making them a valuable tool for analyzing high-reliability products with accelerated testing methods."}}
{"id": "2506.04405", "pdf": "https://arxiv.org/pdf/2506.04405", "abs": "https://arxiv.org/abs/2506.04405", "authors": ["Ran Xu", "Yuchen Zhuang", "Yishan Zhong", "Yue Yu", "Xiangru Tang", "Hang Wu", "May D. Wang", "Peifeng Ruan", "Donghan Yang", "Tao Wang", "Guanghua Xiao", "Carl Yang", "Yang Xie", "Wenqi Shi"], "title": "MedAgentGym: Training LLM Agents for Code-Based Medical Reasoning at Scale", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "We introduce MedAgentGYM, the first publicly available training environment\ndesigned to enhance coding-based medical reasoning capabilities in large\nlanguage model (LLM) agents. MedAgentGYM comprises 72,413 task instances across\n129 categories derived from authentic real-world biomedical scenarios. Tasks\nare encapsulated within executable coding environments, each featuring detailed\ntask descriptions, interactive feedback mechanisms, verifiable ground-truth\nannotations, and scalable training trajectory generation. Extensive\nbenchmarking of over 30 LLMs reveals a notable performance disparity between\ncommercial API-based models and open-source counterparts. Leveraging\nMedAgentGYM, Med-Copilot-7B achieves substantial performance gains through\nsupervised fine-tuning (+36.44%) and continued reinforcement learning\n(+42.47%), emerging as an affordable and privacy-preserving alternative\ncompetitive with gpt-4o. By offering both a comprehensive benchmark and\naccessible, expandable training resources within unified execution\nenvironments, MedAgentGYM delivers an integrated platform to develop LLM-based\ncoding assistants for advanced biomedical research and practice.", "AI": {"tldr": "The paper introduces MedAgentGYM, a training environment for enhancing medical reasoning in LLMs, with extensive benchmarks and performance improvements.", "motivation": "To improve the medical reasoning capabilities of LLMs by providing a comprehensive training environment and benchmarking platform.", "method": "Developed MedAgentGYM, a dataset of 72,413 task instances across 129 categories, using real-world biomedical scenarios. Tasks are encapsulated in executable coding environments with detailed descriptions, interactive feedback, and verifiable ground-truth annotations.", "result": "Med-Copilot-7B, a 7B parameter model, achieved significant performance gains through supervised fine-tuning (+36.44%) and continued reinforcement learning (+42.47%), making it competitive with gpt-4.", "conclusion": "MedAgentGYM is a valuable resource for developing and benchmarking LLM-based coding assistants in biomedical research and practice, offering expandable and accessible training environments."}}
{"id": "2506.04401", "pdf": "https://arxiv.org/pdf/2506.04401", "abs": "https://arxiv.org/abs/2506.04401", "authors": ["Gustavo Perez", "Stella X. Yu"], "title": "Normalize Filters! Classical Wisdom for Deep Vision", "categories": ["cs.CV"], "comment": null, "summary": "Classical image filters, such as those for averaging or differencing, are\ncarefully normalized to ensure consistency, interpretability, and to avoid\nartifacts like intensity shifts, halos, or ringing. In contrast, convolutional\nfilters learned end-to-end in deep networks lack such constraints. Although\nthey may resemble wavelets and blob/edge detectors, they are not normalized in\nthe same or any way. Consequently, when images undergo atmospheric transfer,\ntheir responses become distorted, leading to incorrect outcomes. We address\nthis limitation by proposing filter normalization, followed by learnable\nscaling and shifting, akin to batch normalization. This simple yet effective\nmodification ensures that the filters are atmosphere-equivariant, enabling\nco-domain symmetry. By integrating classical filtering principles into deep\nlearning (applicable to both convolutional neural networks and\nconvolution-dependent vision transformers), our method achieves significant\nimprovements on artificial and natural intensity variation benchmarks. Our\nResNet34 could even outperform CLIP by a large margin. Our analysis reveals\nthat unnormalized filters degrade performance, whereas filter normalization\nregularizes learning, promotes diversity, and improves robustness and\ngeneralization.", "AI": {"tldr": "The paper introduces filter normalization in deep networks to address the issue of filter responses becoming distorted during atmospheric transfer, leading to incorrect outcomes. This method, inspired by batch normalization, ensures atmosphere-equivariant filters and improves performance on various benchmarks.", "motivation": "The motivation is to address the limitations of unnormalized convolutional filters in deep networks, which can lead to artifacts and incorrect responses when images undergo atmospheric transfer. The authors aim to integrate classical filtering principles into deep learning to enhance the robustness and generalization of these models.", "method": "The proposed method involves normalizing the convolutional filters, followed by learnable scaling and shifting, similar to batch normalization. This ensures that the filters are atmosphere-equivariant and maintains co-domain symmetry. The method is applied to both convolutional neural networks and convolution-dependent vision transformers.", "result": "The method achieves significant improvements on artificial and natural intensity variation benchmarks. Specifically, a ResNet34 model with the proposed normalization outperforms CLIP by a large margin. The analysis shows that unnormalized filters degrade performance, while filter normalization regularizes learning, promotes diversity, and enhances robustness and generalization.", "conclusion": "The authors conclude that filter normalization is a simple yet effective modification that integrates classical filtering principles into deep learning. It improves the performance and robustness of deep networks, making them more reliable in various imaging conditions."}}
{"id": "2506.04410", "pdf": "https://arxiv.org/pdf/2506.04410", "abs": "https://arxiv.org/abs/2506.04410", "authors": ["Peter Jansen", "Samiah Hassan", "Ruoyao Wang"], "title": "Matter-of-Fact: A Benchmark for Verifying the Feasibility of Literature-Supported Claims in Materials Science", "categories": ["cs.AI", "cond-mat.mtrl-sci", "cs.CL"], "comment": "8 pages", "summary": "Contemporary approaches to assisted scientific discovery use language models\nto automatically generate large numbers of potential hypothesis to test, while\nalso automatically generating code-based experiments to test those hypotheses.\nWhile hypotheses can be comparatively inexpensive to generate, automated\nexperiments can be costly, particularly when run at scale (i.e. thousands of\nexperiments). Developing the capacity to filter hypotheses based on their\nfeasibility would allow discovery systems to run at scale, while increasing\ntheir likelihood of making significant discoveries. In this work we introduce\nMatter-of-Fact, a challenge dataset for determining the feasibility of\nhypotheses framed as claims. Matter-of-Fact includes 8.4k claims extracted from\nscientific articles spanning four high-impact contemporary materials science\ntopics, including superconductors, semiconductors, batteries, and aerospace\nmaterials, while including qualitative and quantitative claims from\ntheoretical, experimental, and code/simulation results. We show that strong\nbaselines that include retrieval augmented generation over scientific\nliterature and code generation fail to exceed 72% performance on this task\n(chance performance is 50%), while domain-expert verification suggests nearly\nall are solvable -- highlighting both the difficulty of this task for current\nmodels, and the potential to accelerate scientific discovery by making\nnear-term progress.", "AI": {"tldr": "This paper introduces Matter-of-Fact, a dataset to determine the feasibility of scientific hypotheses, which can help reduce the cost of automated experiments.", "motivation": "To address the high cost of running large-scale automated experiments, the paper aims to develop a method to filter hypotheses based on their feasibility.", "method": "The method involves creating a dataset called Matter-of-Fact, which contains 8.4k claims from high-impact materials science topics, and evaluating baseline models for feasibility prediction.", "result": "The baseline models, including retrieval-augmented generation and code generation, achieve a maximum performance of 72% on the task, while domain experts suggest that nearly all claims are feasible in reality.", "conclusion": "The difficulty of the task for current models highlights the potential for significant advancements in accelerating scientific discovery by improving the ability to predict hypothesis feasibility."}}
{"id": "2506.05116", "pdf": "https://arxiv.org/pdf/2506.05116", "abs": "https://arxiv.org/abs/2506.05116", "authors": ["Jiang Hu", "Jiahui Xie", "Yangchun Zhang", "Wang Zhou"], "title": "The Spurious Factor Dilemma: Robust Inference in Heavy-Tailed Elliptical Factor Models", "categories": ["stat.ME", "econ.EM", "math.ST", "stat.TH"], "comment": null, "summary": "Factor models are essential tools for analyzing high-dimensional data,\nparticularly in economics and finance. However, standard methods for\ndetermining the number of factors often overestimate the true number when data\nexhibit heavy-tailed randomness, misinterpreting noise-induced outliers as\ngenuine factors. This paper addresses this challenge within the framework of\nElliptical Factor Models (EFM), which accommodate both heavy tails and\npotential non-linear dependencies common in real-world data. We demonstrate\ntheoretically and empirically that heavy-tailed noise generates spurious\neigenvalues that mimic true factor signals. To distinguish these, we propose a\nnovel methodology based on a fluctuation magnification algorithm. We show that\nunder magnifying perturbations, the eigenvalues associated with real factors\nexhibit significantly less fluctuation (stabilizing asymptotically) compared to\nspurious eigenvalues arising from heavy-tailed effects. This differential\nbehavior allows the identification and detection of the true and spurious\nfactors. We develop a formal testing procedure based on this principle and\napply it to the problem of accurately selecting the number of common factors in\nheavy-tailed EFMs. Simulation studies and real data analysis confirm the\neffectiveness of our approach compared to existing methods, particularly in\nscenarios with pronounced heavy-tailedness.", "AI": {"tldr": "The paper proposes a novel fluctuation magnification algorithm to accurately determine the number of factors in Elliptical Factor Models (EFM) with heavy-tailed data, addressing the issue of overestimation by standard methods.", "motivation": "Standard methods often overestimate the number of factors in factor models when data exhibit heavy-tailed randomness, misinterpreting noise-induced outliers as genuine factors. This paper aims to address this challenge.", "method": "The paper introduces a fluctuation magnification algorithm that distinguishes between real and spurious eigenvalues by observing their behavior under magnifying perturbations. Real factors exhibit less fluctuation (stabilizing asymptotically) compared to spurious eigenvalues from heavy-tailed noise.", "result": "Simulation studies and real data analysis show that the proposed method effectively and accurately selects the number of common factors in heavy-tailed EFMs, outperforming existing methods, especially in scenarios with pronounced heavy-tailedness.", "conclusion": "The fluctuation magnification algorithm provides a robust solution for identifying the true number of factors in heavy-tailed data, improving the reliability of factor models in economics and finance."}}
{"id": "2506.04408", "pdf": "https://arxiv.org/pdf/2506.04408", "abs": "https://arxiv.org/abs/2506.04408", "authors": ["Wesley Scivetti", "Tatsuya Aoyama", "Ethan Wilcox", "Nathan Schneider"], "title": "Unpacking Let Alone: Human-Scale Models Generalize to a Rare Construction in Form but not Meaning", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Humans have a remarkable ability to acquire and understand grammatical\nphenomena that are seen rarely, if ever, during childhood. Recent evidence\nsuggests that language models with human-scale pretraining data may possess a\nsimilar ability by generalizing from frequent to rare constructions. However,\nit remains an open question how widespread this generalization ability is, and\nto what extent this knowledge extends to meanings of rare constructions, as\nopposed to just their forms. We fill this gap by testing human-scale\ntransformer language models on their knowledge of both the form and meaning of\nthe (rare and quirky) English LET-ALONE construction. To evaluate our LMs we\nconstruct a bespoke synthetic benchmark that targets syntactic and semantic\nproperties of the construction. We find that human-scale LMs are sensitive to\nform, even when related constructions are filtered from the dataset. However,\nhuman-scale LMs do not make correct generalizations about LET-ALONE's meaning.\nThese results point to an asymmetry in the current architectures' sample\nefficiency between language form and meaning, something which is not present in\nhuman language learners.", "AI": {"tldr": "This study tests human-scale LMs on their knowledge of the English LET-ALONE construction, finding that while LMs are sensitive to form, they fail to generalize its meaning correctly.", "motivation": "To understand the extent to which human-scale pre-trained language models can generalize from frequent to rare grammatical constructions, particularly in terms of both form and meaning.", "method": "The researchers created a synthetic benchmark to test human-scale transformer LMs on their knowledge of the form and meaning of the rare English LET-ALONE construction.", "result": "The LMs demonstrated sensitivity to the form of the construction even when related constructions were filtered out, but they did not correctly generalize its meaning.", "conclusion": "The results highlight an asymmetry in the sample efficiency of current language model architectures between language form and meaning, which is not observed in human language learners."}}
{"id": "2506.04421", "pdf": "https://arxiv.org/pdf/2506.04421", "abs": "https://arxiv.org/abs/2506.04421", "authors": ["Hermann Kumbong", "Xian Liu", "Tsung-Yi Lin", "Ming-Yu Liu", "Xihui Liu", "Ziwei Liu", "Daniel Y. Fu", "Christopher R\u00e9", "David W. Romero"], "title": "HMAR: Efficient Hierarchical Masked Auto-Regressive Image Generation", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Accepted to CVPR 2025. Project Page:\n  https://research.nvidia.com/labs/dir/hmar/", "summary": "Visual Auto-Regressive modeling (VAR) has shown promise in bridging the speed\nand quality gap between autoregressive image models and diffusion models. VAR\nreformulates autoregressive modeling by decomposing an image into successive\nresolution scales. During inference, an image is generated by predicting all\nthe tokens in the next (higher-resolution) scale, conditioned on all tokens in\nall previous (lower-resolution) scales. However, this formulation suffers from\nreduced image quality due to the parallel generation of all tokens in a\nresolution scale; has sequence lengths scaling superlinearly in image\nresolution; and requires retraining to change the sampling schedule.\n  We introduce Hierarchical Masked Auto-Regressive modeling (HMAR), a new image\ngeneration algorithm that alleviates these issues using next-scale prediction\nand masked prediction to generate high-quality images with fast sampling. HMAR\nreformulates next-scale prediction as a Markovian process, wherein the\nprediction of each resolution scale is conditioned only on tokens in its\nimmediate predecessor instead of the tokens in all predecessor resolutions.\nWhen predicting a resolution scale, HMAR uses a controllable multi-step masked\ngeneration procedure to generate a subset of the tokens in each step. On\nImageNet 256x256 and 512x512 benchmarks, HMAR models match or outperform\nparameter-matched VAR, diffusion, and autoregressive baselines. We develop\nefficient IO-aware block-sparse attention kernels that allow HMAR to achieve\nfaster training and inference times over VAR by over 2.5x and 1.75x\nrespectively, as well as over 3x lower inference memory footprint. Finally,\nHMAR yields additional flexibility over VAR; its sampling schedule can be\nchanged without further training, and it can be applied to image editing tasks\nin a zero-shot manner.", "AI": {"tldr": "HMAR is a new image generation algorithm that addresses the issues of VAR by using next-scale prediction and masked generation, improving image quality and efficiency.", "motivation": "The motivation is to improve the visual quality and efficiency of image generation, addressing the limitations of previous methods such as VAR, which suffer from reduced image quality, superlinear sequence length scaling, and the need for retraining to change sampling schedules.", "method": "HMAR reformulates next-scale prediction as a Markovian process, conditioning each resolution scale on its immediate predecessor and using a multi-step masked generation procedure to generate a subset of tokens in each step.", "result": "HMAR matches or outperforms parameter-matched VAR, diffusion, and autoregressive baselines on ImageNet 256x256 and 512x512 benchmarks, and achieves faster training and inference times with a lower memory footprint.", "conclusion": "HMAR provides additional flexibility, allowing for changes in sampling schedules without retraining and enabling zero-shot image editing."}}
{"id": "2506.04427", "pdf": "https://arxiv.org/pdf/2506.04427", "abs": "https://arxiv.org/abs/2506.04427", "authors": ["Xixi Wang", "Miguel Costa", "Jordanka Kovaceva", "Shuai Wang", "Francisco C. Pereira"], "title": "Plugging Schema Graph into Multi-Table QA: A Human-Guided Framework for Reducing LLM Reliance", "categories": ["cs.AI"], "comment": "Submitted to EMNLP 2025", "summary": "Large language models (LLMs) have shown promise in table Question Answering\n(Table QA). However, extending these capabilities to multi-table QA remains\nchallenging due to unreliable schema linking across complex tables. Existing\nmethods based on semantic similarity work well only on simplified hand-crafted\ndatasets and struggle to handle complex, real-world scenarios with numerous and\ndiverse columns. To address this, we propose a graph-based framework that\nleverages human-curated relational knowledge to explicitly encode schema links\nand join paths. Given a natural language query, our method searches this graph\nto construct interpretable reasoning chains, aided by pruning and sub-path\nmerging strategies to enhance efficiency and coherence. Experiments on both\nstandard benchmarks and a realistic, large-scale dataset demonstrate the\neffectiveness of our approach. To our knowledge, this is the first multi-table\nQA system applied to truly complex industrial tabular data.", "AI": {"tldr": "A new graph-based framework is proposed to improve multi-table QA by leveraging human-curated relational knowledge, enhancing schema linking and query interpretation in complex industrial datasets.", "motivation": "Existing LLMs struggle with multi-table QA, especially in complex, real-world scenarios due to unreliable schema linking. The proposed method aims to enhance schema linking and reasoning for more accurate and interpretable answers.", "method": "The method uses a graph-based framework with human-curated relational knowledge to encode schema links and join paths. It constructs reasoning chains by searching the graph and includes pruning and sub-path merging strategies to improve efficiency and coherence.", "result": "Experiments on standard benchmarks and a large-scale, realistic dataset show that the proposed approach is effective in handling complex industrial tabular data.", "conclusion": "This is the first multi-table QA system applied to complex industrial tabular data, demonstrating significant improvements over existing methods."}}
{"id": "2506.05188", "pdf": "https://arxiv.org/pdf/2506.05188", "abs": "https://arxiv.org/abs/2506.05188", "authors": ["Moritz Miller", "Bernhard Sch\u00f6lkopf", "Siyuan Guo"], "title": "Counterfactual reasoning: an analysis of in-context emergence", "categories": ["cs.CL", "cs.AI", "cs.LG", "math.ST", "stat.TH"], "comment": null, "summary": "Large-scale neural language models (LMs) exhibit remarkable performance in\nin-context learning: the ability to learn and reason the input context on the\nfly without parameter update. This work studies in-context counterfactual\nreasoning in language models, that is, to predict the consequences of changes\nunder hypothetical scenarios. We focus on studying a well-defined synthetic\nsetup: a linear regression task that requires noise abduction, where accurate\nprediction is based on inferring and copying the contextual noise from factual\nobservations. We show that language models are capable of counterfactual\nreasoning in this controlled setup and provide insights that counterfactual\nreasoning for a broad class of functions can be reduced to a transformation on\nin-context observations; we find self-attention, model depth, and data\ndiversity in pre-training drive performance in Transformers. More\ninterestingly, our findings extend beyond regression tasks and show that\nTransformers can perform noise abduction on sequential data, providing\npreliminary evidence on the potential for counterfactual story generation. Our\ncode is available under\nhttps://github.com/moXmiller/counterfactual-reasoning.git .", "AI": {"tldr": "This paper explores in-context counterfactual reasoning in large-scale neural language models, demonstrating their ability to predict consequences of changes in hypothetical scenarios, particularly in a linear regression task involving noise abduction. The study also provides insights into the factors driving performance in Transformers and suggests potential applications in counterfactual story generation.", "motivation": "To understand the capabilities of large-scale neural language models in counterfactual reasoning, which involves predicting outcomes under hypothetical scenarios, and to explore the underlying mechanisms and potential applications.", "method": "The authors study counterfactual reasoning in a controlled synthetic setup using a linear regression task that requires noise abduction. They analyze the performance of language models in this task and investigate the impact of self-attention, model depth, and data diversity in pre-training.", "result": "Language models are capable of counterfactual reasoning in the controlled setup, with performance influenced by self-attention, model depth, and data diversity. The findings extend to sequential data, suggesting potential for counterfactual story generation.", "conclusion": "The study provides evidence that large-scale language models can perform in-context counterfactual reasoning, which could have broader implications for tasks requiring hypothetical reasoning and story generation."}}
{"id": "2506.04409", "pdf": "https://arxiv.org/pdf/2506.04409", "abs": "https://arxiv.org/abs/2506.04409", "authors": ["Lev Morozov", "Aleksandr Mogilevskii", "Alexander Shirnin"], "title": "Empaths at SemEval-2025 Task 11: Retrieval-Augmented Approach to Perceived Emotions Prediction", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted to SemEval-2025, an ACL 2025 workshop", "summary": "This paper describes EmoRAG, a system designed to detect perceived emotions\nin text for SemEval-2025 Task 11, Subtask A: Multi-label Emotion Detection. We\nfocus on predicting the perceived emotions of the speaker from a given text\nsnippet, labeling it with emotions such as joy, sadness, fear, anger, surprise,\nand disgust. Our approach does not require additional model training and only\nuses an ensemble of models to predict emotions. EmoRAG achieves results\ncomparable to the best performing systems, while being more efficient,\nscalable, and easier to implement.", "AI": {"tldr": "EmoRAG is a system for multi-label emotion detection in text that achieves comparable results to the best systems without additional model training, using an ensemble of models.", "motivation": "To detect perceived emotions in text for the SemEval-2025 Task 11, Subtask A, focusing on predicting the emotions of the speaker from a text snippet.", "method": "Uses an ensemble of models to predict emotions without additional model training.", "result": "Achieves results comparable to the best performing systems, while being more efficient, scalable, and easier to implement.", "conclusion": "EmoRAG is a competitive and practical solution for multi-label emotion detection in text."}}
{"id": "2506.04444", "pdf": "https://arxiv.org/pdf/2506.04444", "abs": "https://arxiv.org/abs/2506.04444", "authors": ["Zhaoyang Lv", "Maurizio Monge", "Ka Chen", "Yufeng Zhu", "Michael Goesele", "Jakob Engel", "Zhao Dong", "Richard Newcombe"], "title": "Photoreal Scene Reconstruction from an Egocentric Device", "categories": ["cs.CV", "cs.AI", "cs.GR", "cs.HC", "cs.MM"], "comment": "Paper accepted to SIGGRAPH Conference Paper 2025", "summary": "In this paper, we investigate the challenges associated with using egocentric\ndevices to photorealistic reconstruct the scene in high dynamic range. Existing\nmethodologies typically assume using frame-rate 6DoF pose estimated from the\ndevice's visual-inertial odometry system, which may neglect crucial details\nnecessary for pixel-accurate reconstruction. This study presents two\nsignificant findings. Firstly, in contrast to mainstream work treating RGB\ncamera as global shutter frame-rate camera, we emphasize the importance of\nemploying visual-inertial bundle adjustment (VIBA) to calibrate the precise\ntimestamps and movement of the rolling shutter RGB sensing camera in a high\nfrequency trajectory format, which ensures an accurate calibration of the\nphysical properties of the rolling-shutter camera. Secondly, we incorporate a\nphysical image formation model based into Gaussian Splatting, which effectively\naddresses the sensor characteristics, including the rolling-shutter effect of\nRGB cameras and the dynamic ranges measured by sensors. Our proposed\nformulation is applicable to the widely-used variants of Gaussian Splats\nrepresentation. We conduct a comprehensive evaluation of our pipeline using the\nopen-source Project Aria device under diverse indoor and outdoor lighting\nconditions, and further validate it on a Meta Quest3 device. Across all\nexperiments, we observe a consistent visual enhancement of +1 dB in PSNR by\nincorporating VIBA, with an additional +1 dB achieved through our proposed\nimage formation model. Our complete implementation, evaluation datasets, and\nrecording profile are available at\nhttp://www.projectaria.com/photoreal-reconstruction/", "AI": {"tldr": "This paper addresses the challenges of photorealistic scene reconstruction using egocentric devices, introducing VIBA for precise camera calibration and a physical image formation model for Gaussian Splatting, leading to improved PSNR.", "motivation": "The motivation is to overcome the limitations of existing methodologies that often neglect crucial details in high dynamic range photorealistic scene reconstruction using egocentric devices.", "method": "The paper introduces two key methods: 1) Visual-Inertial Bundle Adjustment (VIBA) to calibrate the precise timestamps and movement of the rolling-shutter RGB camera, and 2) a physical image formation model integrated into Gaussian Splatting to address sensor characteristics and dynamic ranges.", "result": "The proposed methods result in a consistent visual enhancement of +1 dB in PSNR through VIBA, with an additional +1 dB achieved through the physical image formation model.", "conclusion": "The study concludes that the proposed methods significantly improve the accuracy and quality of photorealistic scene reconstruction using egocentric devices, as validated through comprehensive evaluations on both Project Aria and Meta Quest3 devices."}}
{"id": "2506.04429", "pdf": "https://arxiv.org/pdf/2506.04429", "abs": "https://arxiv.org/abs/2506.04429", "authors": ["Ananya Joshi", "Nolan Gormley", "Richa Gadgil", "Tina Townes", "Roni Rosenfeld", "Bryan Wilder"], "title": "An AI-Based Public Health Data Monitoring System", "categories": ["cs.AI"], "comment": null, "summary": "Public health experts need scalable approaches to monitor large volumes of\nhealth data (e.g., cases, hospitalizations, deaths) for outbreaks or data\nquality issues. Traditional alert-based monitoring systems struggle with modern\npublic health data monitoring systems for several reasons, including that\nalerting thresholds need to be constantly reset and the data volumes may cause\napplication lag. Instead, we propose a ranking-based monitoring paradigm that\nleverages new AI anomaly detection methods. Through a multi-year\ninterdisciplinary collaboration, the resulting system has been deployed at a\nnational organization to monitor up to 5,000,000 data points daily. A\nthree-month longitudinal deployed evaluation revealed a significant improvement\nin monitoring objectives, with a 54x increase in reviewer speed efficiency\ncompared to traditional alert-based methods. This work highlights the potential\nof human-centered AI to transform public health decision-making.", "AI": {"tldr": "A scalable ranking-based monitoring system using AI anomaly detection methods has been deployed to monitor up to 5,000,000 data points daily, resulting in a 54x increase in reviewer speed efficiency compared to traditional methods.", "motivation": "To address the limitations of traditional alert-based monitoring systems in handling large volumes of public health data, which include the need for constant threshold resetting and potential application lag.", "method": "The development of a ranking-based monitoring system that leverages AI anomaly detection methods, deployed through a multi-year interdisciplinary collaboration.", "result": "The deployed system significantly improved monitoring objectives, with a 54x increase in reviewer speed efficiency compared to traditional alert-based methods.", "conclusion": "The study highlights the potential of human-centered AI to enhance public health decision-making, demonstrating significant improvements in monitoring large volumes of health data."}}
{"id": "2506.05200", "pdf": "https://arxiv.org/pdf/2506.05200", "abs": "https://arxiv.org/abs/2506.05200", "authors": ["Gen Li", "Yuchen Jiao", "Yu Huang", "Yuting Wei", "Yuxin Chen"], "title": "Transformers Meet In-Context Learning: A Universal Approximation Theory", "categories": ["cs.LG", "math.ST", "stat.ML", "stat.TH"], "comment": null, "summary": "Modern large language models are capable of in-context learning, the ability\nto perform new tasks at inference time using only a handful of input-output\nexamples in the prompt, without any fine-tuning or parameter updates. We\ndevelop a universal approximation theory to better understand how transformers\nenable in-context learning. For any class of functions (each representing a\ndistinct task), we demonstrate how to construct a transformer that, without any\nfurther weight updates, can perform reliable prediction given only a few\nin-context examples. In contrast to much of the recent literature that frames\ntransformers as algorithm approximators -- i.e., constructing transformers to\nemulate the iterations of optimization algorithms as a means to approximate\nsolutions of learning problems -- our work adopts a fundamentally different\napproach rooted in universal function approximation. This alternative approach\noffers approximation guarantees that are not constrained by the effectiveness\nof the optimization algorithms being approximated, thereby extending far beyond\nconvex problems and linear function classes. Our construction sheds light on\nhow transformers can simultaneously learn general-purpose representations and\nadapt dynamically to in-context examples.", "AI": {"tldr": "The paper develops a theory for understanding in-context learning in transformers, focusing on universal function approximation rather than algorithm approximation, allowing transformers to perform tasks reliably with few examples without further weight updates.", "motivation": "To better understand and formalize the mechanism behind in-context learning in transformers, which allows them to perform new tasks using only a few examples in the prompt without fine-tuning.", "method": "The authors construct a transformer that can perform reliable predictions for any class of functions (tasks) given a few in-context examples, using a universal function approximation approach rather than approximating optimization algorithms.", "result": "The constructed transformer can perform tasks reliably with few in-context examples, providing approximation guarantees that are not limited by the effectiveness of optimization algorithms, extending beyond convex problems and linear function classes.", "conclusion": "The paper\u2019s approach offers a new perspective on how transformers can learn general-purpose representations and adapt dynamically to in-context examples, contributing to a deeper understanding of in-context learning in large language models."}}
{"id": "2506.04458", "pdf": "https://arxiv.org/pdf/2506.04458", "abs": "https://arxiv.org/abs/2506.04458", "authors": ["Xueqiang Xu", "Jinfeng Xiao", "James Barry", "Mohab Elkaref", "Jiaru Zou", "Pengcheng Jiang", "Yunyi Zhang", "Max Giammona", "Geeth de Mel", "Jiawei Han"], "title": "Zero-Shot Open-Schema Entity Structure Discovery", "categories": ["cs.CL"], "comment": "14 pages, 3 figures", "summary": "Entity structure extraction, which aims to extract entities and their\nassociated attribute-value structures from text, is an essential task for text\nunderstanding and knowledge graph construction. Existing methods based on large\nlanguage models (LLMs) typically rely heavily on predefined entity attribute\nschemas or annotated datasets, often leading to incomplete extraction results.\nTo address these challenges, we introduce Zero-Shot Open-schema Entity\nStructure Discovery (ZOES), a novel approach to entity structure extraction\nthat does not require any schema or annotated samples. ZOES operates via a\nprincipled mechanism of enrichment, refinement, and unification, based on the\ninsight that an entity and its associated structure are mutually reinforcing.\nExperiments demonstrate that ZOES consistently enhances LLMs' ability to\nextract more complete entity structures across three different domains,\nshowcasing both the effectiveness and generalizability of the method. These\nfindings suggest that such an enrichment, refinement, and unification mechanism\nmay serve as a principled approach to improving the quality of LLM-based entity\nstructure discovery in various scenarios.", "AI": {"tldr": "Proposes ZOES, a zero-shot open-schema entity structure extraction method that improves LLMs' ability to extract complete entity structures without predefined schemas or annotated datasets.", "motivation": "To address the limitations of existing LLM-based methods in entity structure extraction, which often rely on predefined schemas or annotated datasets and can lead to incomplete results.", "method": "ZOES operates through three main steps: enrichment (expanding the initial entity structure), refinement (improving the accuracy of the extracted structure), and unification (integrating multiple structures into a coherent one).", "result": "Experiments show that ZOES enhances LLMs' ability to extract more complete entity structures across three different domains, demonstrating its effectiveness and generalizability.", "conclusion": "The enrichment, refinement, and unification mechanism in ZOES can be a principled approach to improving the quality of LLM-based entity structure discovery in various scenarios."}}
{"id": "2506.04496", "pdf": "https://arxiv.org/pdf/2506.04496", "abs": "https://arxiv.org/abs/2506.04496", "authors": ["Patrik Mesec", "Alan Jovi\u0107"], "title": "Towards Large-Scale Pose-Invariant Face Recognition Using Face Defrontalization", "categories": ["cs.CV"], "comment": "13 pages, 5 figures, 4 tables", "summary": "Face recognition under extreme head poses is a challenging task. Ideally, a\nface recognition system should perform well across different head poses, which\nis known as pose-invariant face recognition. To achieve pose invariance,\ncurrent approaches rely on sophisticated methods, such as face frontalization\nand various facial feature extraction model architectures. However, these\nmethods are somewhat impractical in real-life settings and are typically\nevaluated on small scientific datasets, such as Multi-PIE. In this work, we\npropose the inverse method of face frontalization, called face\ndefrontalization, to augment the training dataset of facial feature extraction\nmodel. The method does not introduce any time overhead during the inference\nstep. The method is composed of: 1) training an adapted face defrontalization\nFFWM model on a frontal-profile pairs dataset, which has been preprocessed\nusing our proposed face alignment method; 2) training a ResNet-50 facial\nfeature extraction model based on ArcFace loss on a raw and randomly\ndefrontalized large-scale dataset, where defrontalization was performed with\nour previously trained face defrontalization model. Our method was compared\nwith the existing approaches on four open-access datasets: LFW, AgeDB, CFP, and\nMulti-PIE. Defrontalization shows improved results compared to models without\ndefrontalization, while the proposed adjustments show clear superiority over\nthe state-of-the-art face frontalization FFWM method on three larger\nopen-access datasets, but not on the small Multi-PIE dataset for extreme poses\n(75 and 90 degrees). The results suggest that at least some of the current\nmethods may be overfitted to small datasets.", "AI": {"tldr": "The paper proposes a novel method called face defrontalization to augment the training dataset of facial feature extraction models, leading to improved pose-invariant face recognition performance on large-scale datasets.", "motivation": "To address the challenge of pose-invariant face recognition, this paper aims to improve the robustness of face recognition systems across different head poses, particularly in real-life settings where existing methods are impractical.", "method": "The proposed method involves training a face defrontalization model (adapted from the FFWM model) to augment the training data for a ResNet-50 facial feature extraction model, which is trained using ArcFace loss. The defrontalization step is applied during training but not during inference to avoid time overhead.", "result": "The method outperformed existing approaches on three large-scale open-access datasets (LFW, AgeDB, and CFP), but not on the small Multi-PIE dataset for extreme poses (75 and 90 degrees). This suggests that the proposed method is more effective on larger datasets and that some existing methods may be overfitted to small datasets.", "conclusion": "The proposed face defrontalization method effectively augments training data, leading to improved pose-invariant face recognition performance on large-scale datasets. However, it does not outperform existing methods on small datasets with extreme poses, indicating a need for further investigation and potential improvements."}}
{"id": "2506.04478", "pdf": "https://arxiv.org/pdf/2506.04478", "abs": "https://arxiv.org/abs/2506.04478", "authors": ["Hadi Hosseini", "Samarth Khanna", "Ronak Singh"], "title": "Matching Markets Meet LLMs: Algorithmic Reasoning with Ranked Preferences", "categories": ["cs.AI", "cs.GT", "econ.TH", "I.2.6; I.2.11; J.4"], "comment": null, "summary": "The rise of Large Language Models (LLMs) has driven progress in reasoning\ntasks -- from program synthesis to scientific hypothesis generation -- yet\ntheir ability to handle ranked preferences and structured algorithms in\ncombinatorial domains remains underexplored. We study matching markets, a core\nframework behind applications like resource allocation and ride-sharing, which\nrequire reconciling individual ranked preferences to ensure stable outcomes. We\nevaluate several state-of-the-art models on a hierarchy of preference-based\nreasoning tasks -- ranging from stable-matching generation to instability\ndetection, instability resolution, and fine-grained preference queries -- to\nsystematically expose their logical and algorithmic limitations in handling\nranked inputs. Surprisingly, even top-performing models with advanced reasoning\nstruggle to resolve instability in large markets, often failing to identify\nblocking pairs or execute algorithms iteratively. We further show that\nparameter-efficient fine-tuning (LoRA) significantly improves performance in\nsmall markets, but fails to bring about a similar improvement on large\ninstances, suggesting the need for more sophisticated strategies to improve\nLLMs' reasoning with larger-context inputs.", "AI": {"tldr": "LLMs struggle with handling ranked preferences and complex algorithms in combinatorial domains, particularly in large markets. Fine-tuning with LoRA helps in small markets but not in large ones.", "motivation": "To explore the limitations of LLMs in handling ranked preferences and structured algorithms in combinatorial domains like matching markets, which are crucial for applications such as resource allocation and ride-sharing.", "method": "Evaluate state-of-the-art LLMs on a hierarchy of preference-based reasoning tasks, including stable-matching generation, instability detection, instability resolution, and preference queries, to systematically identify their limitations.", "result": "Top-performing LLMs struggle with resolving instability in large markets, often failing to identify blocking pairs or execute algorithms iteratively. Fine-tuning with LoRA improves performance in small markets but not in large ones.", "conclusion": "More sophisticated strategies are needed to improve LLMs' reasoning capabilities with larger-context inputs in combinatorial domains."}}
{"id": "2506.04462", "pdf": "https://arxiv.org/pdf/2506.04462", "abs": "https://arxiv.org/abs/2506.04462", "authors": ["Apurv Verma", "NhatHai Phan", "Shubhendu Trivedi"], "title": "Watermarking Degrades Alignment in Language Models: Analysis and Mitigation", "categories": ["cs.CL", "cs.CR", "cs.LG", "I.2.7"], "comment": "Published at the 1st Workshop on GenAI Watermarking, collocated with\n  ICLR 2025. OpenReview: https://openreview.net/forum?id=SIBkIV48gF", "summary": "Watermarking techniques for large language models (LLMs) can significantly\nimpact output quality, yet their effects on truthfulness, safety, and\nhelpfulness remain critically underexamined. This paper presents a systematic\nanalysis of how two popular watermarking approaches-Gumbel and KGW-affect these\ncore alignment properties across four aligned LLMs. Our experiments reveal two\ndistinct degradation patterns: guard attenuation, where enhanced helpfulness\nundermines model safety, and guard amplification, where excessive caution\nreduces model helpfulness. These patterns emerge from watermark-induced shifts\nin token distribution, surfacing the fundamental tension that exists between\nalignment objectives.\n  To mitigate these degradations, we propose Alignment Resampling (AR), an\ninference-time sampling method that uses an external reward model to restore\nalignment. We establish a theoretical lower bound on the improvement in\nexpected reward score as the sample size is increased and empirically\ndemonstrate that sampling just 2-4 watermarked generations effectively recovers\nor surpasses baseline (unwatermarked) alignment scores. To overcome the limited\nresponse diversity of standard Gumbel watermarking, our modified implementation\nsacrifices strict distortion-freeness while maintaining robust detectability,\nensuring compatibility with AR. Experimental results confirm that AR\nsuccessfully recovers baseline alignment in both watermarking approaches, while\nmaintaining strong watermark detectability. This work reveals the critical\nbalance between watermark strength and model alignment, providing a simple\ninference-time solution to responsibly deploy watermarked LLMs in practice.", "AI": {"tldr": "This paper analyzes the impact of two watermarking techniques (Gumbel and KGW) on the alignment properties of large language models (LLMs), revealing two degradation patterns: guard attenuation and guard amplification. It introduces Alignment Resampling (AR), an inference-time method that restores alignment by using an external reward model, demonstrating that sampling 2-4 watermarked generations can recover or surpass baseline alignment scores while maintaining watermark detectability.", "motivation": "The motivation is to understand how watermarking techniques affect the truthfulness, safety, and helpfulness of aligned LLMs and to propose a method to mitigate any negative effects, ensuring the responsible deployment of watermarked LLMs.", "method": "The study conducts experiments on four aligned LLMs to analyze the impact of Gumbel and KGW watermarking techniques. It identifies two degradation patterns and proposes Alignment Resampling (AR), an inference-time method that uses an external reward model to restore alignment. The paper also establishes a theoretical lower bound on the improvement in expected reward score with increased sample size and tests the effectiveness of AR with modified Gumbel watermarking.", "result": "The experiments reveal two degradation patterns (guard attenuation and guard amplification) and show that AR effectively recovers or surpasses baseline alignment scores with just 2-4 watermarked generations. The modified Gumbel implementation maintains strong watermark detectability while improving response diversity.", "conclusion": "The paper concludes that there is a critical balance between watermark strength and model alignment. AR provides a simple inference-time solution to responsibly deploy watermarked LLMs, ensuring that alignment properties are maintained without compromising watermark detectability."}}
{"id": "2506.04499", "pdf": "https://arxiv.org/pdf/2506.04499", "abs": "https://arxiv.org/abs/2506.04499", "authors": ["Shizhong Han", "Hsin-Pai Cheng", "Hong Cai", "Jihad Masri", "Soyeb Nagori", "Fatih Porikli"], "title": "FALO: Fast and Accurate LiDAR 3D Object Detection on Resource-Constrained Devices", "categories": ["cs.CV"], "comment": null, "summary": "Existing LiDAR 3D object detection methods predominantely rely on sparse\nconvolutions and/or transformers, which can be challenging to run on\nresource-constrained edge devices, due to irregular memory access patterns and\nhigh computational costs. In this paper, we propose FALO, a hardware-friendly\napproach to LiDAR 3D detection, which offers both state-of-the-art (SOTA)\ndetection accuracy and fast inference speed. More specifically, given the 3D\npoint cloud and after voxelization, FALO first arranges sparse 3D voxels into a\n1D sequence based on their coordinates and proximity. The sequence is then\nprocessed by our proposed ConvDotMix blocks, consisting of large-kernel\nconvolutions, Hadamard products, and linear layers. ConvDotMix provides\nsufficient mixing capability in both spatial and embedding dimensions, and\nintroduces higher-order nonlinear interaction among spatial features.\nFurthermore, when going through the ConvDotMix layers, we introduce implicit\ngrouping, which balances the tensor dimensions for more efficient inference and\ntakes into account the growing receptive field. All these operations are\nfriendly to run on resource-constrained platforms and proposed FALO can readily\ndeploy on compact, embedded devices. Our extensive evaluation on LiDAR 3D\ndetection benchmarks such as nuScenes and Waymo shows that FALO achieves\ncompetitive performance. Meanwhile, FALO is 1.6~9.8x faster than the latest\nSOTA on mobile Graphics Processing Unit (GPU) and mobile Neural Processing Unit\n(NPU).", "AI": {"tldr": "A new LiDAR 3D object detection method, FALO, is proposed, offering high accuracy and fast inference suitable for resource-constrained edge devices.", "motivation": "To address the high computational costs and irregular memory access patterns of existing LiDAR 3D object detection methods, which make them challenging to run on edge devices.", "method": "FALO arranges sparse 3D voxels into a 1D sequence, processes them using ConvDotMix blocks, and introduces implicit grouping to balance tensor dimensions and account for the growing receptive field.", "result": "FALO achieves competitive performance on benchmarks like nuScenes and Waymo, while being 1.6~9.8x faster than the latest SOTA on mobile GPUs and NPUs.", "conclusion": "FALO is a hardware-friendly approach to LiDAR 3D detection, providing both high accuracy and fast inference speeds, suitable for deployment on compact, embedded devices."}}
{"id": "2506.04481", "pdf": "https://arxiv.org/pdf/2506.04481", "abs": "https://arxiv.org/abs/2506.04481", "authors": ["Jiayu Liu", "Zhenya Huang", "Wei Dai", "Cheng Cheng", "Jinze Wu", "Jing Sha", "Song Li", "Qi Liu", "Shijin Wang", "Enhong Chen"], "title": "CogMath: Assessing LLMs' Authentic Mathematical Ability from a Human Cognitive Perspective", "categories": ["cs.AI"], "comment": null, "summary": "Although large language models (LLMs) show promise in solving complex\nmathematical tasks, existing evaluation paradigms rely solely on a coarse\nmeasure of overall answer accuracy, which are insufficient for assessing their\nauthentic capabilities. In this paper, we propose \\textbf{CogMath}, which\ncomprehensively assesses LLMs' mathematical abilities through the lens of human\ncognition. Specifically, inspired by psychological theories, CogMath formalizes\nhuman reasoning process into 3 stages: \\emph{problem comprehension},\n\\emph{problem solving}, and \\emph{solution summarization}. Within these stages,\nwe investigate perspectives such as numerical calculation, knowledge, and\ncounterfactuals, and design a total of 9 fine-grained evaluation dimensions. In\neach dimension, we develop an ``\\emph{Inquiry}-\\emph{Judge}-\\emph{Reference}''\nmulti-agent system to generate inquiries that assess LLMs' mastery from this\ndimension. An LLM is considered to truly master a problem only when excelling\nin all inquiries from the 9 dimensions. By applying CogMath on three\nbenchmarks, we reveal that the mathematical capabilities of 7 mainstream LLMs\nare overestimated by 30\\%-40\\%. Moreover, we locate their strengths and\nweaknesses across specific stages/dimensions, offering in-depth insights to\nfurther enhance their reasoning abilities.", "AI": {"tldr": "The paper proposes CogMath, a framework to comprehensively evaluate LLMs' mathematical abilities, revealing that their capabilities are often overestimated and providing insights into their strengths and weaknesses.", "motivation": "The motivation is to address the limitations of existing evaluation methods for LLMs in mathematical tasks, which only measure overall accuracy and are insufficient for assessing true capabilities.", "method": "The paper introduces CogMath, a framework that evaluates LLMs' mathematical abilities through 3 stages: problem comprehension, problem solving, and solution summarization, using 9 fine-grained evaluation dimensions. An 'Inquiry-Judge-Reference' multi-agent system is employed to assess LLMs' mastery in each dimension.", "result": "Applying CogMath to three benchmarks, it was found that the mathematical capabilities of 7 mainstream LLMs are overestimated by 30%-40%. The framework also identifies specific strengths and weaknesses of the LLMs in various dimensions.", "conclusion": "CogMath provides a more comprehensive and accurate evaluation of LLMs' mathematical abilities, revealing overestimations and offering insights to improve their reasoning skills."}}
{"id": "2506.04463", "pdf": "https://arxiv.org/pdf/2506.04463", "abs": "https://arxiv.org/abs/2506.04463", "authors": ["Zhaoxuan Tan", "Zheng Li", "Tianyi Liu", "Haodong Wang", "Hyokun Yun", "Ming Zeng", "Pei Chen", "Zhihan Zhang", "Yifan Gao", "Ruijie Wang", "Priyanka Nigam", "Bing Yin", "Meng Jiang"], "title": "Aligning Large Language Models with Implicit Preferences from User-Generated Content", "categories": ["cs.CL"], "comment": "Accepted to ACL 2025 Main Conference", "summary": "Learning from preference feedback is essential for aligning large language\nmodels (LLMs) with human values and improving the quality of generated\nresponses. However, existing preference learning methods rely heavily on\ncurated data from humans or advanced LLMs, which is costly and difficult to\nscale. In this work, we present PUGC, a novel framework that leverages implicit\nhuman Preferences in unlabeled User-Generated Content (UGC) to generate\npreference data. Although UGC is not explicitly created to guide LLMs in\ngenerating human-preferred responses, it often reflects valuable insights and\nimplicit preferences from its creators that has the potential to address\nreaders' questions. PUGC transforms UGC into user queries and generates\nresponses from the policy model. The UGC is then leveraged as a reference text\nfor response scoring, aligning the model with these implicit preferences. This\napproach improves the quality of preference data while enabling scalable,\ndomain-specific alignment. Experimental results on Alpaca Eval 2 show that\nmodels trained with DPO and PUGC achieve a 9.37% performance improvement over\ntraditional methods, setting a 35.93% state-of-the-art length-controlled win\nrate using Mistral-7B-Instruct. Further studies highlight gains in reward\nquality, domain-specific alignment effectiveness, robustness against UGC\nquality, and theory of mind capabilities. Our code and dataset are available at\nhttps://zhaoxuan.info/PUGC.github.io/", "AI": {"tldr": "The paper introduces PUGC, a framework that uses user-generated content (UGC) to generate preference data for aligning large language models (LLMs) with human values, improving the quality of generated responses and achieving better performance over traditional methods.", "motivation": "The motivation is to address the high cost and scalability issues associated with existing preference learning methods for LLMs, which rely on curated data from humans or advanced LLMs.", "method": "PUGC leverages implicit human preferences in unlabeled user-generated content (UGC) by transforming UGC into user queries, generating responses from the policy model, and using the UGC as a reference text for response scoring.", "result": "Experimental results on Alpaca Eval 2 show a 9.37% performance improvement over traditional methods, achieving a 35.93% state-of-the-art length-controlled win rate using Mistral-7B-Instruct. Additional studies demonstrate gains in reward quality, domain-specific alignment, robustness to UGC quality, and theory of mind capabilities.", "conclusion": "The PUGC framework improves the quality and scalability of preference data, enabling better alignment of LLMs with human preferences and enhancing various aspects of model performance."}}
{"id": "2506.04501", "pdf": "https://arxiv.org/pdf/2506.04501", "abs": "https://arxiv.org/abs/2506.04501", "authors": ["Guangyu Shen", "Zhihua Li", "Xiang Xu", "Tianchen Zhao", "Zheng Zhang", "Dongsheng An", "Zhuowen Tu", "Yifan Xing", "Qin Zhang"], "title": "AuthGuard: Generalizable Deepfake Detection via Language Guidance", "categories": ["cs.CV"], "comment": null, "summary": "Existing deepfake detection techniques struggle to keep-up with the\never-evolving novel, unseen forgeries methods. This limitation stems from their\nreliance on statistical artifacts learned during training, which are often tied\nto specific generation processes that may not be representative of samples from\nnew, unseen deepfake generation methods encountered at test time. We propose\nthat incorporating language guidance can improve deepfake detection\ngeneralization by integrating human-like commonsense reasoning -- such as\nrecognizing logical inconsistencies and perceptual anomalies -- alongside\nstatistical cues. To achieve this, we train an expert deepfake vision encoder\nby combining discriminative classification with image-text contrastive\nlearning, where the text is generated by generalist MLLMs using few-shot\nprompting. This allows the encoder to extract both language-describable,\ncommonsense deepfake artifacts and statistical forgery artifacts from\npixel-level distributions. To further enhance robustness, we integrate data\nuncertainty learning into vision-language contrastive learning, mitigating\nnoise in image-text supervision. Our expert vision encoder seamlessly\ninterfaces with an LLM, further enabling more generalized and interpretable\ndeepfake detection while also boosting accuracy. The resulting framework,\nAuthGuard, achieves state-of-the-art deepfake detection accuracy in both\nin-distribution and out-of-distribution settings, achieving AUC gains of 6.15%\non the DFDC dataset and 16.68% on the DF40 dataset. Additionally, AuthGuard\nsignificantly enhances deepfake reasoning, improving performance by 24.69% on\nthe DDVQA dataset.", "AI": {"tldr": "The paper proposes AuthGuard, a deepfake detection method that uses a vision encoder trained with language guidance to improve generalization and accuracy across different datasets and unseen forgeries.", "motivation": "To address the limitations of current deepfake detection methods, which rely on statistical artifacts and struggle with new, unseen deepfake generation techniques, the authors introduce language guidance to incorporate human-like commonsense reasoning.", "method": "The method combines a vision encoder trained with discriminative classification and image-text contrastive learning, leveraging text generated by generalist MLLMs. Data uncertainty learning is also integrated to improve robustness. The vision encoder interfaces with an LLM to enhance generalized and interpretable deepfake detection.", "result": "AuthGuard achieves state-of-the-art deepfake detection accuracy, with AUC gains of 6.15% on the DFDC dataset and 16.68% on the DF40 dataset. It also significantly improves deepfake reasoning, with a 24.69% performance gain on the DDVQA dataset.", "conclusion": "The proposed AuthGuard framework demonstrates significant improvements in deepfake detection and reasoning, making it more robust and accurate in both in-distribution and out-of-distribution settings."}}
{"id": "2506.04500", "pdf": "https://arxiv.org/pdf/2506.04500", "abs": "https://arxiv.org/abs/2506.04500", "authors": ["Aladin Djuhera", "Amin Seffo", "Masataro Asai", "Holger Boche"], "title": "\"Don't Do That!\": Guiding Embodied Systems through Large Language Model-based Constraint Generation", "categories": ["cs.AI", "cs.RO"], "comment": "Preprint; under review", "summary": "Recent advancements in large language models (LLMs) have spurred interest in\nrobotic navigation that incorporates complex spatial, mathematical, and\nconditional constraints from natural language into the planning problem. Such\nconstraints can be informal yet highly complex, making it challenging to\ntranslate into a formal description that can be passed on to a planning\nalgorithm. In this paper, we propose STPR, a constraint generation framework\nthat uses LLMs to translate constraints (expressed as instructions on ``what\nnot to do'') into executable Python functions. STPR leverages the LLM's strong\ncoding capabilities to shift the problem description from language into\nstructured and transparent code, thus circumventing complex reasoning and\navoiding potential hallucinations. We show that these LLM-generated functions\naccurately describe even complex mathematical constraints, and apply them to\npoint cloud representations with traditional search algorithms. Experiments in\na simulated Gazebo environment show that STPR ensures full compliance across\nseveral constraints and scenarios, while having short runtimes. We also verify\nthat STPR can be used with smaller, code-specific LLMs, making it applicable to\na wide range of compact models at low inference cost.", "AI": {"tldr": "A framework called STPR uses large language models to translate natural language constraints into executable Python functions for robotic navigation, ensuring full compliance with constraints and short runtimes.", "motivation": "To address the challenge of translating complex, informally expressed natural language constraints into a formal description that can be used in robotic navigation planning algorithms.", "method": "STPR leverages large language models to generate Python functions from natural language instructions, converting constraints into structured and transparent code to avoid complex reasoning and potential hallucinations.", "result": "Experiments in a simulated Gazebo environment demonstrate that STPR ensures full compliance with various constraints and scenarios while maintaining short runtimes. It also works with smaller, code-specific language models, making it applicable to a wide range of compact models at low inference cost.", "conclusion": "STPR effectively translates complex natural language constraints into executable functions for robotic navigation, ensuring compliance and efficiency, and is applicable to a variety of language models."}}
{"id": "2506.04494", "pdf": "https://arxiv.org/pdf/2506.04494", "abs": "https://arxiv.org/abs/2506.04494", "authors": ["Yue Gong", "Chuan Lei", "Xiao Qin", "Kapil Vaidya", "Balakrishnan Narayanaswamy", "Tim Kraska"], "title": "SQLens: An End-to-End Framework for Error Detection and Correction in Text-to-SQL", "categories": ["cs.CL"], "comment": null, "summary": "Text-to-SQL systems translate natural language (NL) questions into SQL\nqueries, enabling non-technical users to interact with structured data. While\nlarge language models (LLMs) have shown promising results on the text-to-SQL\ntask, they often produce semantically incorrect yet syntactically valid\nqueries, with limited insight into their reliability. We propose SQLens, an\nend-to-end framework for fine-grained detection and correction of semantic\nerrors in LLM-generated SQL. SQLens integrates error signals from both the\nunderlying database and the LLM to identify potential semantic errors within\nSQL clauses. It further leverages these signals to guide query correction.\nEmpirical results on two public benchmarks show that SQLens outperforms the\nbest LLM-based self-evaluation method by 25.78% in F1 for error detection, and\nimproves execution accuracy of out-of-the-box text-to-SQL systems by up to 20%.", "AI": {"tldr": "SQLens is a framework that enhances the reliability of LLM-generated SQL queries by detecting and correcting semantic errors, improving error detection by 25.78% and execution accuracy by up to 20%.", "motivation": "LLMs have shown promise in text-to-SQL tasks but often generate semantically incorrect queries, leading to a need for reliable error detection and correction.", "method": "SQLens integrates error signals from the database and the LLM to detect and correct semantic errors in SQL clauses, guiding query corrections based on these signals.", "result": "SQLens outperforms the best LLM-based self-evaluation method by 25.78% in F1 for error detection and improves execution accuracy by up to 20% on two public benchmarks.", "conclusion": "SQLens provides a robust solution for enhancing the reliability of LLM-generated SQL queries, significantly improving both error detection and execution accuracy."}}
{"id": "2506.04513", "pdf": "https://arxiv.org/pdf/2506.04513", "abs": "https://arxiv.org/abs/2506.04513", "authors": ["Gustavo Henrique do Nascimento", "Ian Pons", "Anna Helena Reali Costa", "Artur Jordao"], "title": "Pruning Everything, Everywhere, All at Once", "categories": ["cs.CV"], "comment": "To be published in International Joint Conference on Neural Networks\n  (IJCNN), 2025", "summary": "Deep learning stands as the modern paradigm for solving cognitive tasks.\nHowever, as the problem complexity increases, models grow deeper and\ncomputationally prohibitive, hindering advancements in real-world and\nresource-constrained applications. Extensive studies reveal that pruning\nstructures in these models efficiently reduces model complexity and improves\ncomputational efficiency. Successful strategies in this sphere include removing\nneurons (i.e., filters, heads) or layers, but not both together. Therefore,\nsimultaneously pruning different structures remains an open problem. To fill\nthis gap and leverage the benefits of eliminating neurons and layers at once,\nwe propose a new method capable of pruning different structures within a model\nas follows. Given two candidate subnetworks (pruned models), one from layer\npruning and the other from neuron pruning, our method decides which to choose\nby selecting the one with the highest representation similarity to its parent\n(the network that generates the subnetworks) using the Centered Kernel\nAlignment metric. Iteratively repeating this process provides highly sparse\nmodels that preserve the original predictive ability. Throughout extensive\nexperiments on standard architectures and benchmarks, we confirm the\neffectiveness of our approach and show that it outperforms state-of-the-art\nlayer and filter pruning techniques. At high levels of Floating Point\nOperations reduction, most state-of-the-art methods degrade accuracy, whereas\nour approach either improves it or experiences only a minimal drop. Notably, on\nthe popular ResNet56 and ResNet110, we achieve a milestone of 86.37% and 95.82%\nFLOPs reduction. Besides, our pruned models obtain robustness to adversarial\nand out-of-distribution samples and take an important step towards GreenAI,\nreducing carbon emissions by up to 83.31%. Overall, we believe our work opens a\nnew chapter in pruning.", "AI": {"tldr": "A new method is proposed to simultaneously prune different structures within deep learning models, such as layers and neurons, using the Centered Kernel Alignment metric to maintain high representation similarity with the original model. The method iteratively prunes subnetworks, achieving significant FLOPs reduction and preserving or improving accuracy, while also enhancing robustness and reducing carbon emissions.", "motivation": "The motivation is to overcome the limitations of existing pruning methods that either prune neurons or layers, but not both together, to achieve more efficient and compact models while maintaining or improving performance.", "method": "The proposed method involves creating two candidate subnetworks, one pruned by layers and the other by neurons, and selecting the one with the highest representation similarity to the original model using the Centered Kernel Alignment metric. This process is iteratively applied to produce highly sparse models.", "result": "The method outperforms state-of-the-art layer and filter pruning techniques, achieving 86.37% and 95.82% FLOPs reduction on ResNet56 and ResNet110, respectively, with minimal accuracy degradation or even improvement. It also enhances robustness to adversarial and out-of-distribution samples and reduces carbon emissions by up to 83.31%.", "conclusion": "The proposed method opens a new chapter in pruning by enabling simultaneous layer and neuron pruning, significantly reducing computational complexity while preserving or improving model performance and contributing to GreenAI."}}
{"id": "2506.04512", "pdf": "https://arxiv.org/pdf/2506.04512", "abs": "https://arxiv.org/abs/2506.04512", "authors": ["Bohui Zhang", "Yuan He", "Lydia Pintscher", "Albert Mero\u00f1o Pe\u00f1uela", "Elena Simperl"], "title": "Schema Generation for Large Knowledge Graphs Using Large Language Models", "categories": ["cs.AI"], "comment": null, "summary": "Schemas are vital for ensuring data quality in the Semantic Web and natural\nlanguage processing. Traditionally, their creation demands substantial\ninvolvement from knowledge engineers and domain experts. Leveraging the\nimpressive capabilities of large language models (LLMs) in related tasks like\nontology engineering, we explore automatic schema generation using LLMs. To\nbridge the resource gap, we introduce two datasets: YAGO Schema and Wikidata\nEntitySchema, along with evaluation metrics. The LLM-based pipelines\neffectively utilize local and global information from knowledge graphs (KGs) to\ngenerate validating schemas in Shape Expressions (ShEx). Experiments\ndemonstrate LLMs' strong potential in producing high-quality ShEx schemas,\npaving the way for scalable, automated schema generation for large KGs.\nFurthermore, our benchmark introduces a new challenge for structured\ngeneration, pushing the limits of LLMs on syntactically rich formalisms.", "AI": {"tldr": "This paper explores the use of large language models (LLMs) for automatic schema generation in the Semantic Web and natural language processing, introducing datasets and metrics to evaluate their performance.", "motivation": "The motivation is to reduce the substantial involvement of knowledge engineers and domain experts in schema creation by leveraging the capabilities of LLMs in ontology engineering.", "method": "The method involves using LLMs to generate validating schemas in Shape Expressions (ShEx) from local and global information in knowledge graphs (KGs), and introducing two datasets (YAGO Schema and Wikidata EntitySchema) along with evaluation metrics.", "result": "Experiments show that LLMs have strong potential in producing high-quality ShEx schemas, demonstrating their effectiveness in scalable, automated schema generation for large KGs.", "conclusion": "The paper concludes that LLMs can significantly contribute to automated schema generation, and the introduced benchmark sets a new challenge for structured generation tasks involving syntactically rich formalisms."}}
{"id": "2506.04516", "pdf": "https://arxiv.org/pdf/2506.04516", "abs": "https://arxiv.org/abs/2506.04516", "authors": ["Kun Zhao", "Bohao Yang", "Chen Tang", "Siyuan Dai", "Haoteng Tang", "Chenghua Lin", "Liang Zhan"], "title": "DRE: An Effective Dual-Refined Method for Integrating Small and Large Language Models in Open-Domain Dialogue Evaluation", "categories": ["cs.CL"], "comment": "arXiv admin note: text overlap with arXiv:2405.15924", "summary": "Large Language Models (LLMs) excel at many tasks but struggle with ambiguous\nscenarios where multiple valid responses exist, often yielding unreliable\nresults. Conversely, Small Language Models (SLMs) demonstrate robustness in\nsuch scenarios but are susceptible to misleading or adversarial inputs. We\nobserved that LLMs handle negative examples effectively, while SLMs excel with\npositive examples. To leverage their complementary strengths, we introduce\nSLIDE (Small and Large Integrated for Dialogue Evaluation), a method\nintegrating SLMs and LLMs via adaptive weighting. Building on SLIDE, we further\npropose a Dual-Refinement Evaluation (DRE) method to enhance SLM-LLM\nintegration: (1) SLM-generated insights guide the LLM to produce initial\nevaluations; (2) SLM-derived adjustments refine the LLM's scores for improved\naccuracy. Experiments demonstrate that DRE outperforms existing methods,\nshowing stronger alignment with human judgment across diverse benchmarks. This\nwork illustrates how combining small and large models can yield more reliable\nevaluation tools, particularly for open-ended tasks such as dialogue\nevaluation.", "AI": {"tldr": "The paper introduces SLIDE and DRE, methods that integrate SLMs and LLMs to improve dialogue evaluation, showing better alignment with human judgment.", "motivation": "To leverage the strengths of both SLMs (robust in ambiguous scenarios) and LLMs (effective with negative examples) to improve the reliability of dialogue evaluation.", "method": "SLIDE integrates SLMs and LLMs via adaptive weighting, while DRE uses SLM-generated insights to guide initial LLM evaluations and SLM-derived adjustments to refine LLM scores.", "result": "Experiments demonstrate that DRE outperforms existing methods and aligns better with human judgment across diverse benchmarks.", "conclusion": "Combining SLMs and LLMs can lead to more reliable evaluation tools, especially for open-ended tasks like dialogue evaluation."}}
{"id": "2506.04526", "pdf": "https://arxiv.org/pdf/2506.04526", "abs": "https://arxiv.org/abs/2506.04526", "authors": ["Shuo Zhang"], "title": "EECD-Net: Energy-Efficient Crack Detection with Spiking Neural Networks and Gated Attention", "categories": ["cs.CV"], "comment": null, "summary": "Crack detection on road surfaces is a critical measurement technology in the\ninstrumentation domain, essential for ensuring infrastructure safety and\ntransportation reliability. However, due to limited energy and low-resolution\nimaging, smart terminal devices struggle to maintain real-time monitoring\nperformance. To overcome these challenges, this paper proposes a multi-stage\ndetection approach for road crack detection, EECD-Net, to enhance accuracy and\nenergy efficiency of instrumentation. Specifically, the sophisticated\nSuper-Resolution Convolutional Neural Network (SRCNN) is employed to address\nthe inherent challenges of low-quality images, which effectively enhance image\nresolution while preserving critical structural details. Meanwhile, a Spike\nConvolution Unit (SCU) with Continuous Integrate-and-Fire (CIF) neurons is\nproposed to convert these images into sparse pulse sequences, significantly\nreducing power consumption. Additionally, a Gated Attention Transformer (GAT)\nmodule is designed to strategically fuse multi-scale feature representations\nthrough adaptive attention mechanisms, effectively capturing both long-range\ndependencies and intricate local crack patterns, and significantly enhancing\ndetection robustness across varying crack morphologies. The experiments on the\nCrackVision12K benchmark demonstrate that EECD-Net achieves a remarkable 98.6\\%\ndetection accuracy, surpassing state-of-the-art counterparts such as\nHybrid-Segmentor by a significant 1.5\\%. Notably, the EECD-Net maintains\nexceptional energy efficiency, consuming merely 5.6 mJ, which is a substantial\n33\\% reduction compared to baseline implementations. This work pioneers a\ntransformative approach in instrumentation-based crack detection, offering a\nscalable, low-power solution for real-time, large-scale infrastructure\nmonitoring in resource-constrained environments.", "AI": {"tldr": "The paper introduces EECD-Net, a multi-stage detection approach for road crack detection that improves accuracy and energy efficiency using SRCNN, SCU, and GAT modules. It achieves 98.6% accuracy and consumes 5.6 mJ, a 33% reduction in energy compared to baseline methods.", "motivation": "The motivation is to address the challenges of real-time road crack detection in resource-constrained environments, where smart terminal devices face issues with limited energy and low-resolution imaging.", "method": "EECD-Net combines a Super-Resolution Convolutional Neural Network (SRCNN) to enhance image resolution, a Spike Convolution Unit (SCU) with Continuous Integrate-and-Fire (CIF) neurons to reduce power consumption, and a Gated Attention Transformer (GAT) module to capture both long-range and local crack patterns.", "result": "The proposed EECD-Net achieves 98.6% detection accuracy on the CrackVision12K benchmark, surpassing state-of-the-art methods like Hybrid-Segmentor by 1.5%. It also demonstrates a 33% reduction in energy consumption compared to baseline implementations.", "conclusion": "The paper presents a transformative approach to instrumentation-based crack detection, offering a scalable and low-power solution for real-time infrastructure monitoring in resource-constrained environments."}}
{"id": "2506.04571", "pdf": "https://arxiv.org/pdf/2506.04571", "abs": "https://arxiv.org/abs/2506.04571", "authors": ["Srikanth Thudumu", "Jason Fisher"], "title": "OpenAg: Democratizing Agricultural Intelligence", "categories": ["cs.AI"], "comment": "10 pages, 1 figure", "summary": "Agriculture is undergoing a major transformation driven by artificial\nintelligence (AI), machine learning, and knowledge representation technologies.\nHowever, current agricultural intelligence systems often lack contextual\nunderstanding, explainability, and adaptability, especially for smallholder\nfarmers with limited resources. General-purpose large language models (LLMs),\nwhile powerful, typically lack the domain-specific knowledge and contextual\nreasoning needed for practical decision support in farming. They tend to\nproduce recommendations that are too generic or unrealistic for real-world\napplications. To address these challenges, we present OpenAg, a comprehensive\nframework designed to advance agricultural artificial general intelligence\n(AGI). OpenAg combines domain-specific foundation models, neural knowledge\ngraphs, multi-agent reasoning, causal explainability, and adaptive transfer\nlearning to deliver context-aware, explainable, and actionable insights. The\nsystem includes: (i) a unified agricultural knowledge base that integrates\nscientific literature, sensor data, and farmer-generated knowledge; (ii) a\nneural agricultural knowledge graph for structured reasoning and inference;\n(iii) an adaptive multi-agent reasoning system where AI agents specialize and\ncollaborate across agricultural domains; and (iv) a causal transparency\nmechanism that ensures AI recommendations are interpretable, scientifically\ngrounded, and aligned with real-world constraints. OpenAg aims to bridge the\ngap between scientific knowledge and the tacit expertise of experienced farmers\nto support scalable and locally relevant agricultural decision-making.", "AI": {"tldr": "OpenAg is a framework that integrates domain-specific models, knowledge graphs, multi-agent systems, and causal explainability to provide context-aware and actionable agricultural insights, targeting the needs of smallholder farmers.", "motivation": "Current agricultural intelligence systems lack contextual understanding, explainability, and adaptability, especially for smallholder farmers with limited resources. General-purpose LLMs often provide generic or unrealistic recommendations.", "method": "OpenAg combines: (i) a unified agricultural knowledge base; (ii) a neural agricultural knowledge graph; (iii) an adaptive multi-agent reasoning system; and (iv) a causal transparency mechanism to ensure interpretable and relevant recommendations.", "result": "The framework is designed to deliver context-aware, explainable, and actionable insights, bridging the gap between scientific knowledge and the practical expertise of farmers.", "conclusion": "OpenAg aims to support scalable and locally relevant agricultural decision-making, particularly for smallholder farmers, by leveraging advanced AI and knowledge representation technologies."}}
{"id": "2506.04521", "pdf": "https://arxiv.org/pdf/2506.04521", "abs": "https://arxiv.org/abs/2506.04521", "authors": ["Di Wu", "Seth Aycock", "Christof Monz"], "title": "Please Translate Again: Two Simple Experiments on Whether Human-Like Reasoning Helps Translation", "categories": ["cs.CL"], "comment": "16 pages, 16 figures", "summary": "Large Language Models (LLMs) demonstrate strong reasoning capabilities for\nmany tasks, often by explicitly decomposing the task via Chain-of-Thought (CoT)\nreasoning. Recent work on LLM-based translation designs hand-crafted prompts to\ndecompose translation, or trains models to incorporate intermediate\nsteps.~\\textit{Translating Step-by-step}~\\citep{briakou2024translating}, for\ninstance, introduces a multi-step prompt with decomposition and refinement of\ntranslation with LLMs, which achieved state-of-the-art results on WMT24. In\nthis work, we scrutinise this strategy's effectiveness. Empirically, we find no\nclear evidence that performance gains stem from explicitly decomposing the\ntranslation process, at least for the models on test; and we show that simply\nprompting LLMs to ``translate again'' yields even better results than\nhuman-like step-by-step prompting. Our analysis does not rule out the role of\nreasoning, but instead invites future work exploring the factors for CoT's\neffectiveness in the context of translation.", "AI": {"tldr": "This paper investigates the effectiveness of decomposing translation into multiple steps using Large Language Models (LLMs) and finds that simply prompting LLMs to 'translate again' yields better results than using multi-step prompts.", "motivation": "The motivation is to scrutinize the effectiveness of the step-by-step decomposition approach in LLM-based translation, which has been claimed to improve performance.", "method": "The researchers empirically evaluate the performance of LLMs using multi-step prompts for translation and compare it with the performance achieved by simply prompting the LLMs to 'translate again'.", "result": "The results show no clear evidence that explicitly decomposing the translation process improves performance, and that the 'translate again' approach yields even better results.", "conclusion": "The paper concludes that the effectiveness of Chain-of-Thought (CoT) reasoning in translation is not well understood and invites future work to explore the factors contributing to its effectiveness."}}
{"id": "2506.04555", "pdf": "https://arxiv.org/pdf/2506.04555", "abs": "https://arxiv.org/abs/2506.04555", "authors": ["Heng Tian"], "title": "Enhancing Frequency for Single Image Super-Resolution with Learnable Separable Kernels", "categories": ["cs.CV", "cs.MM"], "comment": null, "summary": "Existing approaches often enhance the performance of single-image\nsuper-resolution (SISR) methods by incorporating auxiliary structures, such as\nspecialized loss functions, to indirectly boost the quality of low-resolution\nimages. In this paper, we propose a plug-and-play module called Learnable\nSeparable Kernels (LSKs), which are formally rank-one matrices designed to\ndirectly enhance image frequency components. We begin by explaining why LSKs\nare particularly suitable for SISR tasks from a frequency perspective. Baseline\nmethods incorporating LSKs demonstrate a significant reduction of over 60\\% in\nboth the number of parameters and computational requirements. This reduction is\nachieved through the decomposition of LSKs into orthogonal and mergeable\none-dimensional kernels. Additionally, we perform an interpretable analysis of\nthe feature maps generated by LSKs. Visualization results reveal the capability\nof LSKs to enhance image frequency components effectively. Extensive\nexperiments show that incorporating LSKs not only reduces the number of\nparameters and computational load but also improves overall model performance.\nMoreover, these experiments demonstrate that models utilizing LSKs exhibit\nsuperior performance, particularly as the upscaling factor increases.", "AI": {"tldr": "The paper introduces Learnable Separable Kernels (LSKs) to directly enhance image frequency components in single-image super-resolution (SISR) tasks, reducing parameters and computational requirements while improving performance.", "motivation": "The motivation is to enhance the performance of SISR methods by directly manipulating image frequency components, addressing the limitations of existing approaches that rely on auxiliary structures.", "method": "LSKs are rank-one matrices that decompose into orthogonal and mergeable one-dimensional kernels, directly enhancing image frequency components. They are integrated into baseline SISR methods to reduce parameters and computational load.", "result": "Incorporating LSKs leads to a significant reduction of over 60% in parameters and computational requirements, while improving overall model performance, especially at higher upscaling factors.", "conclusion": "LSKs effectively enhance image frequency components, reduce computational complexity, and improve SISR performance, making them a valuable addition to existing SISR methods."}}
{"id": "2506.04610", "pdf": "https://arxiv.org/pdf/2506.04610", "abs": "https://arxiv.org/abs/2506.04610", "authors": ["Guido Governatori", "Antonino Rotolo"], "title": "Judicial Permission", "categories": ["cs.AI", "cs.CY", "cs.LO"], "comment": null, "summary": "This paper examines the significance of weak permissions in criminal trials\n(\\emph{judicial permission}). It introduces a dialogue game model to\nsystematically address judicial permissions, considering different standards of\nproof and argumentation semantics.", "AI": {"tldr": "The paper explores the importance of weak permissions in criminal trials and proposes a dialogue game model to address them, considering various proof standards and argumentation semantics.", "motivation": "The motivation is to improve the understanding and handling of judicial permissions in criminal trials, which can influence the outcome of cases.", "method": "The method involves the development of a dialogue game model that incorporates different standards of proof and argumentation semantics to systematically address judicial permissions.", "result": "The paper likely presents insights into how the dialogue game model can better clarify and manage weak permissions in criminal trials, potentially leading to more fair and just outcomes.", "conclusion": "The conclusion likely emphasizes the potential benefits of using the dialogue game model in judicial settings and suggests further research or practical applications."}}
{"id": "2506.04534", "pdf": "https://arxiv.org/pdf/2506.04534", "abs": "https://arxiv.org/abs/2506.04534", "authors": ["William Sheffield", "Kanishka Misra", "Valentina Pyatkin", "Ashwini Deo", "Kyle Mahowald", "Junyi Jessy Li"], "title": "Is It JUST Semantics? A Case Study of Discourse Particle Understanding in LLMs", "categories": ["cs.CL", "cs.AI"], "comment": "To be published in Findings of The 63rd Annual Meeting of the\n  Association for Computational Linguistics (ACL 2025). The main paper is 5\n  pages and contains 3 figures and 1 table. In total, the paper is 12 pages and\n  contains 8 figures and 5 tables (References + Appendix)", "summary": "Discourse particles are crucial elements that subtly shape the meaning of\ntext. These words, often polyfunctional, give rise to nuanced and often quite\ndisparate semantic/discourse effects, as exemplified by the diverse uses of the\nparticle \"just\" (e.g., exclusive, temporal, emphatic). This work investigates\nthe capacity of LLMs to distinguish the fine-grained senses of English \"just\",\na well-studied example in formal semantics, using data meticulously created and\nlabeled by expert linguists. Our findings reveal that while LLMs exhibit some\nability to differentiate between broader categories, they struggle to fully\ncapture more subtle nuances, highlighting a gap in their understanding of\ndiscourse particles.", "AI": {"tldr": "This paper examines the ability of large language models (LLMs) to distinguish the nuanced meanings of the English discourse particle 'just', revealing that while LLMs can differentiate broader categories, they struggle with finer semantic distinctions.", "motivation": "The motivation is to assess the understanding of fine-grained semantic distinctions in discourse particles by LLMs, focusing on the well-studied particle 'just' to highlight the limitations and capabilities of these models.", "method": "The study uses data meticulously created and labeled by expert linguists to evaluate the performance of LLMs in distinguishing the various senses of 'just'.", "result": "The findings show that while LLMs can differentiate between broader categories of 'just', they struggle with capturing more subtle nuances.", "conclusion": "The paper concludes that there is a significant gap in the ability of LLMs to fully understand and capture the nuanced meanings of discourse particles like 'just'."}}
{"id": "2506.04559", "pdf": "https://arxiv.org/pdf/2506.04559", "abs": "https://arxiv.org/abs/2506.04559", "authors": ["Yunhao Gou", "Kai Chen", "Zhili Liu", "Lanqing Hong", "Xin Jin", "Zhenguo Li", "James T. Kwok", "Yu Zhang"], "title": "Perceptual Decoupling for Scalable Multi-modal Reasoning via Reward-Optimized Captioning", "categories": ["cs.CV"], "comment": null, "summary": "Recent advances in slow-thinking language models (e.g., OpenAI-o1 and\nDeepSeek-R1) have demonstrated remarkable abilities in complex reasoning tasks\nby emulating human-like reflective cognition. However, extending such\ncapabilities to multi-modal large language models (MLLMs) remains challenging\ndue to the high cost of retraining vision-language alignments when upgrading\nthe underlying reasoner LLMs. A straightforward solution is to decouple\nperception from reasoning, i.e., converting visual inputs into language\nrepresentations (e.g., captions) that are then passed to a powerful text-only\nreasoner. However, this decoupling introduces a critical challenge: the visual\nextractor must generate descriptions that are both faithful to the image and\ninformative enough to support accurate downstream reasoning. To address this,\nwe propose Reasoning-Aligned Perceptual Decoupling via Caption Reward\nOptimization (RACRO) - a reasoning-guided reinforcement learning strategy that\naligns the extractor's captioning behavior with the reasoning objective. By\nclosing the perception-reasoning loop via reward-based optimization, RACRO\nsignificantly enhances visual grounding and extracts reasoning-optimized\nrepresentations. Experiments on multi-modal math and science benchmarks show\nthat the proposed RACRO method achieves state-of-the-art average performance\nwhile enabling superior scalability and plug-and-play adaptation to more\nadvanced reasoning LLMs without the necessity for costly multi-modal\nre-alignment.", "AI": {"tldr": "The paper introduces RACRO, a method that enhances the alignment between visual perception and reasoning in multi-modal large language models by using a reasoning-guided reinforcement learning strategy, achieving state-of-the-art performance and better scalability.", "motivation": "The motivation is to address the challenge of extending complex reasoning capabilities from text-based LLMs to multi-modal LLMs, specifically focusing on maintaining accurate and informative visual-to-text conversion for downstream reasoning tasks.", "method": "RACRO uses a reasoning-guided reinforcement learning approach to optimize the captioning process, ensuring that the generated captions are both faithful to the visual content and informative for reasoning tasks, effectively closing the perception-reasoning loop.", "result": "Experiments on multi-modal math and science benchmarks demonstrate that RACRO achieves state-of-the-art average performance and enables better scalability and adaptability to more advanced reasoning LLMs without the need for costly retraining.", "conclusion": "The paper concludes that RACRO significantly improves visual grounding and reasoning-optimized representations, making it a promising approach for enhancing multi-modal LLMs while maintaining efficiency and adaptability."}}
